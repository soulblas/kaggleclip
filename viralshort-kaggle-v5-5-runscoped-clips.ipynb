{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e899ce17-e158-40da-aace-b049662acbf7",
      "metadata": {},
      "source": [
        "# üé¨ Viral Short Video Pipeline ‚Äî Production Grade v5.5 v5.5 (Kaggle)\n",
        "> **Role:** AI Production Engineer & Video Pipeline Architect (editorial-grade)  \n",
        "> **Hard Locks:** ‚úÖ 9:16 FIT + BLACK LETTERBOX ‚Ä¢ ‚úÖ 1080√ó1920 ‚Ä¢ ‚úÖ 30 FPS ‚Ä¢ ‚úÖ Audio 160k ‚Ä¢ ‚úÖ NO CROP/ZOOM ‚Ä¢ ‚úÖ NO FACE ‚Ä¢ ‚úÖ NO SUBTITLE/SRT\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Table of Contents\n",
        "\n",
        "- üß∞ **Stage 0: Config & Environment**\n",
        "- üì• **Stage 1: Ingest Video**\n",
        "- üîä **Stage 2: Audio Analysis (Global)**\n",
        "- üñºÔ∏è **Stage 3: Visual Sampling (Thumbnails Only)**\n",
        "- üéûÔ∏è **Stage 4: Shot Detection (Optional)**\n",
        "- üö´ **Stage 5: No Face Processing (Hard Lock)**\n",
        "- üß© **Stage 6: Segment Proposal (Candidate Mining)**\n",
        "- üß™ **Stage 7: Feature Extraction**\n",
        "- üó£Ô∏è **Stage 8: ASR (QUALITY Mode + Cache + Heartbeat)**\n",
        "- üßÆ **Stage 9: Scoring (Audit-able, Percentile-Based)**\n",
        "- üß≠ **Stage 10: Deterministic Selection + Diversity + Timeline Sanity**\n",
        "- ‚úÇÔ∏è **Stage 11: Cut Rules (Snap to Word/Silence + Avoid Shot-Cut)**\n",
        "- üì¶ **Stage 12: Export (9:16 FIT + Letterbox)**\n",
        "- üßæ **Stage 13: Manifest (JSON/CSV + Caption/Hashtag)**\n",
        "- ‚úÖ **Stage 14: Acceptance Tests & Summary**\n",
        "\n",
        "---\n",
        "\n",
        "## üìÇ Locked I/O Contract\n",
        "\n",
        "### Input (LOCKED)\n",
        "- Video MP4/MKV: `/kaggle/input/<dataset>/*`\n",
        "\n",
        "### Output (LOCKED)\n",
        "- `/kaggle/working/outputs/clips/*.mp4`  \n",
        "- `/kaggle/working/outputs/thumbnails/*.jpg`  \n",
        "- `/kaggle/working/manifest.json`  \n",
        "- `/kaggle/working/manifest.csv`\n",
        "\n",
        "### Run Folder (LOCKED)\n",
        "```\n",
        "/kaggle/working/\n",
        "  outputs/\n",
        "    clips/\n",
        "    thumbnails/\n",
        "  runs/\n",
        "    run_<timestamp>/\n",
        "      cache/\n",
        "      logs/\n",
        "      artifacts/\n",
        "        audio.wav\n",
        "        silence_segments.json\n",
        "        speech_blocks.json\n",
        "        transcript.json\n",
        "        candidates.json\n",
        "        selected.json\n",
        "      manifest.json\n",
        "      manifest.csv\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bfb4fa54-78af-4ac7-a082-fb0af303bef1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-30T12:04:22.128464Z",
          "iopub.status.busy": "2026-01-30T12:04:22.128180Z",
          "iopub.status.idle": "2026-01-30T12:04:22.158137Z",
          "shell.execute_reply": "2026-01-30T12:04:22.157244Z",
          "shell.execute_reply.started": "2026-01-30T12:04:22.128434Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-31 02:25:09,270 | INFO | RUN_DIR: \\kaggle\\working\\runs\\run_20260130_192509\n",
            "2026-01-31 02:25:09,271 | INFO | Hard Locks: NO_FACE=True NO_CROP_ZOOM=True NO_SUBTITLES=True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# Stage 0: Config & Env\n",
        "# =========================\n",
        "\n",
        "import os, sys, json, math, time, re, csv, subprocess, logging\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime, timezone\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "\n",
        "# ---------- Hard Locks ----------\n",
        "LOCK_NO_FACE = True\n",
        "LOCK_NO_CROP_ZOOM = True\n",
        "LOCK_NO_SUBTITLES = True\n",
        "\n",
        "# ---------- Export Contract ----------\n",
        "EXPORT_W = 1080\n",
        "EXPORT_H = 1920\n",
        "EXPORT_FPS = 30\n",
        "AUDIO_BITRATE = \"160k\"\n",
        "EXPORT_MODE = \"FIT_PAD_BLACK\"  # FIT + BLACK LETTERBOX\n",
        "\n",
        "# ---------- Clip Contract ----------\n",
        "MIN_CLIP_SEC = 18.0\n",
        "MAX_CLIP_SEC = 60.0\n",
        "HOOK_WINDOW_SEC = 5.0\n",
        "\n",
        "# ---------- Diversity / Selection ----------\n",
        "MAX_FINAL_CLIPS = 6\n",
        "MIN_GAP_SEC = 30.0\n",
        "SEGMENT_DURATION_SEC = 600.0  # 10 minutes\n",
        "MAX_PER_SEGMENT = 2\n",
        "\n",
        "# ---------- ASR ----------\n",
        "ASR_LANGUAGE = \"id\"\n",
        "ASR_ENABLED = True\n",
        "ASR_TOP_PERCENT = 0.40  # transcribe top 40% for scoring; selected-only ASR for snapping if needed\n",
        "MAX_ASR_BLOCK_SEC = 28.0\n",
        "MAX_ASR_BLOCK_WALL_SEC = 45.0\n",
        "ASR_BLOCK_OVERLAP_SEC = 0.25\n",
        "\n",
        "# ---------- Trigger words (markers) ----------\n",
        "TRIGGER_WORDS = [\n",
        "    \"anjir\",\"anjay\",\"gila\",\"serius\",\"beneran\",\"parah\",\"lucuu\",\"ngakak\",\"ketawa\",\n",
        "    \"kok\",\"loh\",\"hah\",\"apaan\",\"buset\",\"astaga\",\"waduh\",\"wkwk\",\"wkwkwk\",\"yaampun\",\n",
        "    \"kaget\",\"plot\",\"twist\",\"tapi\",\"ternyata\",\"eh\",\"coba\",\"sumpah\"\n",
        "]\n",
        "\n",
        "# ---------- Tool Binaries ----------\n",
        "FFMPEG_BIN = \"ffmpeg\"\n",
        "FFPROBE_BIN = \"ffprobe\"\n",
        "\n",
        "# ---------- Run folder (timezone-aware UTC) ----------\n",
        "RUN_TIMESTAMP = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
        "WORKDIR = Path(\"/kaggle/working\")\n",
        "RUN_DIR = WORKDIR / \"runs\" / f\"run_{RUN_TIMESTAMP}\"\n",
        "CACHE_DIR = RUN_DIR / \"cache\"\n",
        "LOG_DIR = RUN_DIR / \"logs\"\n",
        "ART_DIR = RUN_DIR / \"artifacts\"\n",
        "\n",
        "# ‚úÖ LOCKED: per-run outputs (user request)\n",
        "OUT_DIR = RUN_DIR  # keep run artifacts self-contained\n",
        "CLIPS_DIR = OUT_DIR / \"clips\"\n",
        "THUMBS_DIR = OUT_DIR / \"thumbnails\"\n",
        "\n",
        "# Optional convenience mirror (not required for correctness)\n",
        "PUBLIC_OUT_DIR = WORKDIR / \"outputs\"\n",
        "PUBLIC_CLIPS_DIR = PUBLIC_OUT_DIR / \"clips\"\n",
        "PUBLIC_THUMBS_DIR = PUBLIC_OUT_DIR / \"thumbnails\"\n",
        "\n",
        "for p in [CACHE_DIR, LOG_DIR, ART_DIR, CLIPS_DIR, THUMBS_DIR, PUBLIC_CLIPS_DIR, PUBLIC_THUMBS_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- Logging ----------\n",
        "LOG_FILE = LOG_DIR / \"pipeline.log\"\n",
        "\n",
        "logger = logging.getLogger(\"viralshort\")\n",
        "logger.setLevel(logging.INFO)\n",
        "logger.handlers.clear()\n",
        "\n",
        "fmt = logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\")\n",
        "\n",
        "fh = logging.FileHandler(LOG_FILE, encoding=\"utf-8\")\n",
        "fh.setLevel(logging.INFO)\n",
        "fh.setFormatter(fmt)\n",
        "\n",
        "sh = logging.StreamHandler(sys.stdout)\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(fmt)\n",
        "\n",
        "logger.addHandler(fh)\n",
        "logger.addHandler(sh)\n",
        "\n",
        "def log_flush():\n",
        "    for h in logger.handlers:\n",
        "        try: h.flush()\n",
        "        except Exception: pass\n",
        "    try: sys.stdout.flush()\n",
        "    except Exception: pass\n",
        "\n",
        "class StageTimer:\n",
        "    def __init__(self, stage_id: int, name: str):\n",
        "        self.stage_id = stage_id\n",
        "        self.name = name\n",
        "        self.t0 = None\n",
        "        self.dt = None\n",
        "    def __enter__(self):\n",
        "        self.t0 = time.monotonic()\n",
        "        logger.info(f\"[STAGE {self.stage_id:02d}] START - {self.name}\")\n",
        "        log_flush()\n",
        "        return self\n",
        "    def __exit__(self, exc_type, exc, tb):\n",
        "        self.dt = time.monotonic() - self.t0\n",
        "        if exc:\n",
        "            logger.error(f\"[STAGE {self.stage_id:02d}] FAIL  - {self.name} ({self.dt:.2f}s): {exc}\")\n",
        "        else:\n",
        "            logger.info(f\"[STAGE {self.stage_id:02d}] END   - {self.name} ({self.dt:.2f}s)\")\n",
        "        log_flush()\n",
        "        return False\n",
        "\n",
        "def write_json(path: Path, obj: Any):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
        "    logger.info(f\"Wrote: {path}\")\n",
        "\n",
        "def read_json(path: Path) -> Any:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "logger.info(f\"RUN_DIR: {RUN_DIR}\")\n",
        "logger.info(\"Hard Locks: NO_FACE=%s NO_CROP_ZOOM=%s NO_SUBTITLES=%s\", LOCK_NO_FACE, LOCK_NO_CROP_ZOOM, LOCK_NO_SUBTITLES)\n",
        "log_flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "767ab389-f26a-4dc2-bb2a-037c4f8ca188",
      "metadata": {},
      "source": [
        "## üì• Stage 1: Ingest Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6dd2e35a-68af-46ec-9eb0-6b4e44b39863",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-30T12:04:22.161149Z",
          "iopub.status.busy": "2026-01-30T12:04:22.160343Z",
          "iopub.status.idle": "2026-01-30T12:04:23.505229Z",
          "shell.execute_reply": "2026-01-30T12:04:23.504189Z",
          "shell.execute_reply.started": "2026-01-30T12:04:22.161069Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-31 02:25:09,289 | INFO | [STAGE 01] START - Ingest Video\n",
            "2026-01-31 02:25:09,292 | ERROR | [STAGE 01] FAIL  - Ingest Video (0.00s): Missing /kaggle/input (this notebook is for Kaggle).\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Missing /kaggle/input (this notebook is for Kaggle).",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m input_root = Path(\u001b[33m\"\u001b[39m\u001b[33m/kaggle/input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m input_root.exists():\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMissing /kaggle/input (this notebook is for Kaggle).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# pick first mp4/mkv found\u001b[39;00m\n\u001b[32m     12\u001b[39m candidates = []\n",
            "\u001b[31mRuntimeError\u001b[39m: Missing /kaggle/input (this notebook is for Kaggle)."
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# Stage 1: Ingest Video\n",
        "# =========================\n",
        "from glob import glob\n",
        "\n",
        "with StageTimer(1, \"Ingest Video\"):\n",
        "    input_root = Path(\"/kaggle/input\")\n",
        "    if not input_root.exists():\n",
        "        raise RuntimeError(\"Missing /kaggle/input (this notebook is for Kaggle).\")\n",
        "\n",
        "    # pick first mp4/mkv found\n",
        "    candidates = []\n",
        "    for ext in (\"*.mp4\",\"*.mkv\",\"*.mov\",\"*.webm\",\"*.m4v\"):\n",
        "        candidates += list(input_root.rglob(ext))\n",
        "    if not candidates:\n",
        "        raise RuntimeError(\"No video found under /kaggle/input/<dataset>/*\")\n",
        "    VIDEO_PATH = sorted(candidates)[0]\n",
        "    logger.info(f\"Selected video: {VIDEO_PATH}\")\n",
        "\n",
        "    # probe duration + audio presence\n",
        "    cmd = [\n",
        "        FFPROBE_BIN, \"-v\", \"error\", \"-show_entries\",\n",
        "        \"format=duration:stream=codec_type\", \"-of\", \"json\", str(VIDEO_PATH)\n",
        "    ]\n",
        "    meta = json.loads(subprocess.check_output(cmd).decode(\"utf-8\"))\n",
        "    duration = float(meta[\"format\"][\"duration\"])\n",
        "    ANALYZED_DURATION = duration\n",
        "    logger.info(f\"Duration: {ANALYZED_DURATION:.2f}s\")\n",
        "\n",
        "    # store meta\n",
        "    write_json(ART_DIR / \"video_meta.json\", {\"video_path\": str(VIDEO_PATH), \"duration_sec\": ANALYZED_DURATION, \"run_timestamp_utc\": RUN_TIMESTAMP})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ce56dc0-483a-4c0c-8ec7-0fa9348fbbba",
      "metadata": {},
      "source": [
        "## üîä Stage 2: Audio Analysis (Global)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a9aef6-3a05-4a7a-abb3-2989ecdac420",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-30T12:04:23.506929Z",
          "iopub.status.busy": "2026-01-30T12:04:23.506619Z",
          "iopub.status.idle": "2026-01-30T12:04:39.760167Z",
          "shell.execute_reply": "2026-01-30T12:04:39.759320Z",
          "shell.execute_reply.started": "2026-01-30T12:04:23.506902Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-30 12:04:23,520 | INFO | [STAGE 02] START - Audio Extract + Global Analysis\n",
            "2026-01-30 12:04:34,253 | INFO | Audio extracted: /kaggle/working/runs/run_20260130_120422/artifacts/audio.wav\n",
            "2026-01-30 12:04:35,249 | INFO | Wrote: /kaggle/working/runs/run_20260130_120422/artifacts/silence_segments.json\n",
            "2026-01-30 12:04:35,250 | INFO | Wrote silence_segments.json\n",
            "2026-01-30 12:04:35,250 | INFO | Silence segments: 435\n",
            "2026-01-30 12:04:39,753 | INFO | Wrote: /kaggle/working/runs/run_20260130_120422/artifacts/energy_curve.json\n",
            "2026-01-30 12:04:39,754 | INFO | Energy points: 232359 (saved to energy_curve.json)\n",
            "2026-01-30 12:04:39,755 | INFO | [STAGE 02] END   - Audio Extract + Global Analysis (16.24s)\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Stage 2: Audio Analysis (Global)\n",
        "# =========================\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "with StageTimer(2, \"Audio Extract + Global Analysis\"):\n",
        "\n",
        "    AUDIO_WAV = str(ART_DIR / \"audio.wav\")\n",
        "\n",
        "    # Extract mono 16k wav for analysis/ASR\n",
        "    cmd = [\n",
        "        FFMPEG_BIN, \"-y\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
        "        \"-i\", str(VIDEO_PATH),\n",
        "        \"-vn\", \"-ac\", \"1\", \"-ar\", \"16000\", \"-f\", \"wav\", AUDIO_WAV\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True)\n",
        "    logger.info(f\"Audio extracted: {AUDIO_WAV}\")\n",
        "\n",
        "    # -------------------------\n",
        "    # Silence detect (ffmpeg) ‚Äî cached\n",
        "    # -------------------------\n",
        "    sil_path = ART_DIR / \"silence_segments.json\"\n",
        "    if sil_path.exists():\n",
        "        SILENCE_SEGMENTS = read_json(sil_path)\n",
        "        logger.info(\"Loaded cached silence_segments.json\")\n",
        "    else:\n",
        "        silence_cmd = [\n",
        "            FFMPEG_BIN, \"-hide_banner\", \"-loglevel\", \"info\",\n",
        "            \"-i\", AUDIO_WAV,\n",
        "            \"-af\", \"silencedetect=noise=-35dB:d=0.35\",\n",
        "            \"-f\", \"null\", \"-\"\n",
        "        ]\n",
        "        p = subprocess.Popen(silence_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        _, err = p.communicate()\n",
        "\n",
        "        if p.returncode != 0:\n",
        "            logger.warning(\"silencedetect failed; continuing with empty silence list\")\n",
        "            SILENCE_SEGMENTS = []\n",
        "        else:\n",
        "            starts, ends = [], []\n",
        "            for line in err.splitlines():\n",
        "                if \"silence_start\" in line:\n",
        "                    m = re.search(r\"silence_start: ([0-9\\.]+)\", line)\n",
        "                    if m:\n",
        "                        starts.append(float(m.group(1)))\n",
        "                if \"silence_end\" in line:\n",
        "                    m = re.search(r\"silence_end: ([0-9\\.]+)\", line)\n",
        "                    if m:\n",
        "                        ends.append(float(m.group(1)))\n",
        "\n",
        "            SILENCE_SEGMENTS = []\n",
        "            j = 0\n",
        "            for s in starts:\n",
        "                while j < len(ends) and ends[j] < s:\n",
        "                    j += 1\n",
        "                if j < len(ends):\n",
        "                    SILENCE_SEGMENTS.append([s, ends[j]])\n",
        "                    j += 1\n",
        "\n",
        "        write_json(sil_path, SILENCE_SEGMENTS)\n",
        "        logger.info(\"Wrote silence_segments.json\")\n",
        "\n",
        "    logger.info(f\"Silence segments: {len(SILENCE_SEGMENTS)}\")\n",
        "\n",
        "    # -------------------------\n",
        "    # Energy curve (RMS timeline) ‚Äî always written\n",
        "    # -------------------------\n",
        "    ENERGY_CURVE = []  # <-- WAJIB: global variable for Stage 6 fallback\n",
        "\n",
        "    try:\n",
        "        import soundfile as sf\n",
        "        y, sr = sf.read(AUDIO_WAV)\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"soundfile read failed; falling back to scipy.io.wavfile ({e})\")\n",
        "        from scipy.io import wavfile\n",
        "        sr, y = wavfile.read(AUDIO_WAV)\n",
        "\n",
        "        # convert int PCM to float32\n",
        "        if hasattr(y, \"dtype\") and y.dtype != np.float32:\n",
        "            if np.issubdtype(y.dtype, np.integer):\n",
        "                y = y.astype(np.float32) / float(np.iinfo(y.dtype).max)\n",
        "            else:\n",
        "                y = y.astype(np.float32)\n",
        "\n",
        "    if y.ndim > 1:\n",
        "        y = y.mean(axis=1)\n",
        "\n",
        "    hop = int(0.02 * sr)  # 20ms\n",
        "    win = int(0.04 * sr)  # 40ms\n",
        "\n",
        "    for i in range(0, len(y) - win, hop):\n",
        "        frame = y[i:i + win]\n",
        "        val = float(np.sqrt(np.mean(frame * frame)) + 1e-12)\n",
        "        t = float(i / sr)\n",
        "        ENERGY_CURVE.append({\"time\": t, \"rms\": val})\n",
        "\n",
        "    # write to artifacts for audit + Stage 6 load\n",
        "    write_json(ART_DIR / \"energy_curve.json\", ENERGY_CURVE)\n",
        "    logger.info(f\"Energy points: {len(ENERGY_CURVE)} (saved to energy_curve.json)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e990421c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Stage 2.5: Speech Blocks (silence complement + VAD fallback)\n",
        "# =========================\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def _speech_blocks_from_silence(total_dur, silence_segments, pad=0.05):\n",
        "    sil = sorted([[max(0.0, s - pad), min(total_dur, e + pad)] for s, e in (silence_segments or [])], key=lambda x: x[0])\n",
        "    out = []\n",
        "    cur = 0.0\n",
        "    for s, e in sil:\n",
        "        if s > cur:\n",
        "            out.append([cur, s])\n",
        "        cur = max(cur, e)\n",
        "    if cur < total_dur:\n",
        "        out.append([cur, total_dur])\n",
        "    # remove tiny blocks\n",
        "    out = [[s, e] for s, e in out if (e - s) >= 0.6]\n",
        "    return out\n",
        "\n",
        "\n",
        "def _speech_blocks_from_energy(energy_curve, total_dur, thr_pct=60, min_len=0.8, max_gap=0.35):\n",
        "    if not energy_curve:\n",
        "        return []\n",
        "    vals = [float(p.get(\"rms\", 0.0)) for p in energy_curve]\n",
        "    if not vals:\n",
        "        return []\n",
        "    thr = float(np.percentile(vals, thr_pct))\n",
        "    blocks = []\n",
        "    in_speech = False\n",
        "    s = None\n",
        "    last_t = None\n",
        "    for p in energy_curve:\n",
        "        t = float(p.get(\"time\", 0.0))\n",
        "        rms = float(p.get(\"rms\", 0.0))\n",
        "        if rms >= thr:\n",
        "            if not in_speech:\n",
        "                in_speech = True\n",
        "                s = t\n",
        "            last_t = t\n",
        "        else:\n",
        "            if in_speech and last_t is not None:\n",
        "                if (t - last_t) > max_gap:\n",
        "                    e = last_t\n",
        "                    if (e - s) >= min_len:\n",
        "                        blocks.append([s, min(e, total_dur)])\n",
        "                    in_speech = False\n",
        "                    s = None\n",
        "                    last_t = None\n",
        "    if in_speech and s is not None and last_t is not None:\n",
        "        if (last_t - s) >= min_len:\n",
        "            blocks.append([s, min(last_t, total_dur)])\n",
        "    return blocks\n",
        "\n",
        "\n",
        "with StageTimer(2, \"Speech Blocks (silence complement + VAD fallback)\"):\n",
        "    total = float(ANALYZED_DURATION)\n",
        "    speech_blocks = _speech_blocks_from_silence(total, SILENCE_SEGMENTS, pad=0.05)\n",
        "    if not speech_blocks:\n",
        "        logger.warning(\"No speech blocks from silence; using energy VAD fallback\")\n",
        "        speech_blocks = _speech_blocks_from_energy(ENERGY_CURVE, total)\n",
        "\n",
        "    SPEECH_BLOCKS = speech_blocks\n",
        "    write_json(ART_DIR / \"speech_blocks.json\", SPEECH_BLOCKS)\n",
        "    logger.info(f\"Speech blocks: {len(SPEECH_BLOCKS)}\")\n",
        "\n",
        "    if not SPEECH_BLOCKS:\n",
        "        raise RuntimeError(\"SPEECH_BLOCKS missing/empty without fallback\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3886a772-3956-4af5-ac9e-0c7035b8a320",
      "metadata": {},
      "source": [
        "## üñºÔ∏è Stage 3: Visual Sampling (Thumbnails Only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c60968-3067-4ef3-8cc4-2913c3dfbb66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-30T12:04:39.762548Z",
          "iopub.status.busy": "2026-01-30T12:04:39.761995Z",
          "iopub.status.idle": "2026-01-30T12:04:50.346350Z",
          "shell.execute_reply": "2026-01-30T12:04:50.345580Z",
          "shell.execute_reply.started": "2026-01-30T12:04:39.762516Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-30 12:04:39,766 | INFO | [STAGE 03] START - Thumbnails Sampling (No AI)\n",
            "2026-01-30 12:04:50,340 | INFO | Wrote: /kaggle/working/runs/run_20260130_120422/artifacts/thumbnail_samples.json\n",
            "2026-01-30 12:04:50,341 | INFO | Sample thumbnails: 24\n",
            "2026-01-30 12:04:50,342 | INFO | [STAGE 03] END   - Thumbnails Sampling (No AI) (10.58s)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# Stage 3: Visual Sampling (Thumbnails Only)\n",
        "# =========================\n",
        "import random\n",
        "\n",
        "with StageTimer(3, \"Thumbnails Sampling (No AI)\"):\n",
        "    # sample fixed timestamps for thumbnails (deterministic)\n",
        "    random.seed(1337)\n",
        "    n_thumbs = min(24, max(8, int(ANALYZED_DURATION // 30)))\n",
        "    ts = sorted({min(ANALYZED_DURATION-0.1, (i+1)*ANALYZED_DURATION/(n_thumbs+1)) for i in range(n_thumbs)})\n",
        "    thumb_paths = []\n",
        "    for i, t in enumerate(ts, 1):\n",
        "        outp = THUMBS_DIR / f\"sample_{i:02d}_{t:.2f}.jpg\"\n",
        "        cmd = [\n",
        "            FFMPEG_BIN, \"-y\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
        "            \"-ss\", str(t), \"-i\", str(VIDEO_PATH),\n",
        "            \"-vframes\", \"1\", \"-q:v\", \"2\", str(outp)\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True)\n",
        "        thumb_paths.append(str(outp))\n",
        "    write_json(ART_DIR / \"thumbnail_samples.json\", {\"timestamps\": ts, \"paths\": thumb_paths})\n",
        "    logger.info(f\"Sample thumbnails: {len(thumb_paths)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab73a08-3aeb-4e3d-8307-0ec852afa625",
      "metadata": {},
      "source": [
        "## üéûÔ∏è Stage 4: Shot Detection (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ba21cf-65d4-4052-93cb-88409e3019ae",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-30T12:04:50.347798Z",
          "iopub.status.busy": "2026-01-30T12:04:50.347518Z",
          "iopub.status.idle": "2026-01-30T12:04:50.360586Z",
          "shell.execute_reply": "2026-01-30T12:04:50.359417Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.347771Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-30 12:04:50,351 | INFO | [STAGE 04] START - Shot Detection (Optional)\n",
            "2026-01-30 12:04:50,355 | WARNING | Shot detection unavailable; continuing without. (No module named 'scenedetect')\n",
            "2026-01-30 12:04:50,356 | INFO | [STAGE 04] END   - Shot Detection (Optional) (0.00s)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# Stage 4: Shot Detection (Optional)\n",
        "# =========================\n",
        "with StageTimer(4, \"Shot Detection (Optional)\"):\n",
        "    SHOT_CUTS = []\n",
        "    shot_path = ART_DIR / \"shot_cuts.json\"\n",
        "    if shot_path.exists():\n",
        "        SHOT_CUTS = read_json(shot_path)\n",
        "        logger.info(\"Loaded cached shot cuts\")\n",
        "    else:\n",
        "        try:\n",
        "            from scenedetect import open_video, SceneManager\n",
        "            from scenedetect.detectors import ContentDetector\n",
        "\n",
        "            video = open_video(str(VIDEO_PATH))\n",
        "            scene_manager = SceneManager()\n",
        "            scene_manager.add_detector(ContentDetector(threshold=27.0))\n",
        "            scene_manager.detect_scenes(video, show_progress=False)\n",
        "            scene_list = scene_manager.get_scene_list()\n",
        "            # convert to cut timestamps (scene start times excluding 0)\n",
        "            for (start, end) in scene_list[1:]:\n",
        "                SHOT_CUTS.append(float(start.get_seconds()))\n",
        "            write_json(shot_path, SHOT_CUTS)\n",
        "            logger.info(f\"Shot cuts: {len(SHOT_CUTS)}\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Shot detection unavailable; continuing without. ({e})\")\n",
        "            SHOT_CUTS = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a151924-537c-4a40-947e-df7580b5c2a9",
      "metadata": {},
      "source": [
        "## üö´ Stage 5: No Face Processing (Hard Lock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3214ee65-2cd6-4702-a0eb-952cc198b1bc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-30T12:04:50.362500Z",
          "iopub.status.busy": "2026-01-30T12:04:50.362153Z",
          "iopub.status.idle": "2026-01-30T12:04:50.393441Z",
          "shell.execute_reply": "2026-01-30T12:04:50.392351Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.362472Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-30 12:04:50,383 | INFO | [STAGE 05] START - Hard Lock: NO FACE / NO CROP / NO ZOOM\n",
            "2026-01-30 12:04:50,386 | INFO | ‚úÖ This pipeline does not perform face detection/tracking/crop/zoom. Export uses FIT+PAD only.\n",
            "2026-01-30 12:04:50,387 | INFO | ‚úÖ This pipeline does not generate SRT/subtitles or burn-in captions.\n",
            "2026-01-30 12:04:50,388 | INFO | [STAGE 05] END   - Hard Lock: NO FACE / NO CROP / NO ZOOM (0.00s)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# Stage 5: No Face Processing (Hard Lock)\n",
        "# =========================\n",
        "with StageTimer(5, \"Hard Lock: NO FACE / NO CROP / NO ZOOM\"):\n",
        "    # Audit guard: ensure notebook never imports face libs or uses crop/zoom filters intentionally.\n",
        "    banned_tokens = [\n",
        "        \"face_recognition\", \"mediapipe\", \"dlib\", \"mtcnn\", \"retinaface\",\n",
        "        \"insightface\", \"face\", \"facenet\", \"tracking\", \"reframe\", \"zoompan\",\n",
        "        \"crop=\", \"scale=ih*9/16\", \"cropdetect\"\n",
        "    ]\n",
        "    # This is a runtime sanity message, not file scanning.\n",
        "    logger.info(\"‚úÖ This pipeline does not perform face detection/tracking/crop/zoom. Export uses FIT+PAD only.\")\n",
        "    logger.info(\"‚úÖ This pipeline does not generate SRT/subtitles or burn-in captions.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e61596d0-1b8b-4c24-bdc1-473535bb9d54",
      "metadata": {},
      "source": [
        "## üß© Stage 6: Segment Proposal (Candidate Mining)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587c5d43-bb77-4d34-9fab-7393b80a3afc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-30T12:04:50.395190Z",
          "iopub.status.busy": "2026-01-30T12:04:50.394671Z",
          "iopub.status.idle": "2026-01-30T12:04:50.438477Z",
          "shell.execute_reply": "2026-01-30T12:04:50.436324Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.395152Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-30 12:04:50,422 | INFO | [STAGE 06] START - Segment Proposal (Candidate Mining)\n",
            "2026-01-30 12:04:50,425 | ERROR | [STAGE 06] FAIL  - Segment Proposal (Candidate Mining) (0.00s): name 'P97' is not defined\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'P97' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_55/1126285635.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# B) PEAK-CENTRIC WINDOWS (UPGRADE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# =====================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mpeaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mENERGY_CURVE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rms\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mP97\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0mpeaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeaks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeaks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpeaks\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'P97' is not defined"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Stage 6: Segment Proposal (Candidate Mining) ‚Äî FINAL (Flexible Duration End-Seeking)\n",
        "# =========================\n",
        "import numpy as np\n",
        "\n",
        "def complement_intervals(total_end: float, silence_segments: List[List[float]], pad: float=0.0) -> List[List[float]]:\n",
        "    sil = sorted([[max(0.0, s-pad), min(total_end, e+pad)] for s, e in (silence_segments or [])], key=lambda x: x[0])\n",
        "    out = []\n",
        "    cur = 0.0\n",
        "    for s, e in sil:\n",
        "        if s > cur:\n",
        "            out.append([cur, s])\n",
        "        cur = max(cur, e)\n",
        "    if cur < total_end:\n",
        "        out.append([cur, total_end])\n",
        "    return out\n",
        "\n",
        "def get_peak_time(energy_curve, start, end):\n",
        "    pts = [p for p in energy_curve if start <= p[\"time\"] <= end]\n",
        "    if not pts:\n",
        "        return None, None\n",
        "    m = max(pts, key=lambda x: x[\"rms\"])\n",
        "    return float(m[\"time\"]), float(m[\"rms\"])\n",
        "\n",
        "# -------------------------------------------------\n",
        "# FLEXIBLE DURATION (OPSIONAL) ‚Äî end seeking\n",
        "# -------------------------------------------------\n",
        "USE_FLEXIBLE_DUR = os.getenv(\"USE_FLEXIBLE_DUR\", \"1\") == \"1\"\n",
        "\n",
        "MIN_DUR_SEC = float(os.getenv(\"MIN_DUR_SEC\", str(MIN_CLIP_SEC)))\n",
        "MAX_DUR_SEC = float(os.getenv(\"MAX_DUR_SEC\", str(MAX_CLIP_SEC)))\n",
        "\n",
        "# Ideal range hanya preferensi (bukan wajib)\n",
        "IDEAL_DUR_MIN = float(os.getenv(\"IDEAL_DUR_MIN\", \"25\"))\n",
        "IDEAL_DUR_MAX = float(os.getenv(\"IDEAL_DUR_MAX\", \"45\"))\n",
        "\n",
        "# Window cari endpoint natural dekat target/hardcap\n",
        "END_LOOKBACK  = float(os.getenv(\"END_LOOKBACK\", \"3.0\"))\n",
        "END_LOOKAHEAD = float(os.getenv(\"END_LOOKAHEAD\", \"2.0\"))\n",
        "\n",
        "def _best_silence_start_in_window(lo: float, hi: float, target: float, silence_segments: List[List[float]]):\n",
        "    best = None\n",
        "    best_d = None\n",
        "    for s, e in (silence_segments or []):\n",
        "        s = float(s)\n",
        "        if lo <= s <= hi:\n",
        "            d = abs(s - target)\n",
        "            if best_d is None or d < best_d:\n",
        "                best_d = d\n",
        "                best = s\n",
        "    return best\n",
        "\n",
        "def _best_block_end_in_window(lo: float, hi: float, target: float, speech_blocks: List[List[float]]):\n",
        "    best = None\n",
        "    best_d = None\n",
        "    for s, e in (speech_blocks or []):\n",
        "        e = float(e)\n",
        "        if lo <= e <= hi:\n",
        "            d = abs(e - target)\n",
        "            if best_d is None or d < best_d:\n",
        "                best_d = d\n",
        "                best = e\n",
        "    return best\n",
        "\n",
        "def pick_flexible_end(start: float, hard_end: float,\n",
        "                      silence_segments: List[List[float]],\n",
        "                      speech_blocks: List[List[float]]):\n",
        "    \"\"\"\n",
        "    Pilih end natural (durasi opsional):\n",
        "    - Prioritas: silence start, lalu speech-block end\n",
        "    - Ideal range hanya preferensi\n",
        "    - Kalau tidak ada finish point, fallback hard_end\n",
        "    \"\"\"\n",
        "    start = float(start)\n",
        "    hard_end = float(hard_end)\n",
        "\n",
        "    min_end = min(start + MIN_DUR_SEC, hard_end)\n",
        "    if hard_end <= min_end + 0.05:\n",
        "        return hard_end, \"end:video_short\"\n",
        "\n",
        "    # target preferensi: tengah ideal range, tapi tidak melewati hard_end\n",
        "    target = min(start + (IDEAL_DUR_MIN + IDEAL_DUR_MAX) * 0.5, hard_end)\n",
        "\n",
        "    # window pencarian\n",
        "    win_lo = max(min_end, target - END_LOOKBACK)\n",
        "    win_hi = min(hard_end, target + END_LOOKAHEAD)\n",
        "\n",
        "    sil = _best_silence_start_in_window(win_lo, win_hi, target, silence_segments)\n",
        "    if sil is not None:\n",
        "        return float(max(sil, min_end)), \"end:silence_seek\"\n",
        "\n",
        "    blk = _best_block_end_in_window(win_lo, win_hi, target, speech_blocks)\n",
        "    if blk is not None:\n",
        "        return float(max(blk, min_end)), \"end:block_seek\"\n",
        "\n",
        "    # fallback hard cap (terakhir)\n",
        "    return hard_end, \"end:hardcap\"\n",
        "\n",
        "# =====================================================\n",
        "# RMS PEAK THRESHOLD SAFE-INIT (ANTI NameError)\n",
        "# =====================================================\n",
        "def _compute_rms_percentile(energy_curve, q=97):\n",
        "    if not energy_curve:\n",
        "        return None\n",
        "    vals = []\n",
        "    for p in energy_curve:\n",
        "        if isinstance(p, dict) and \"rms\" in p:\n",
        "            try:\n",
        "                vals.append(float(p[\"rms\"]))\n",
        "            except Exception:\n",
        "                pass\n",
        "    if not vals:\n",
        "        return None\n",
        "    try:\n",
        "        return float(np.percentile(vals, q))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# Resolve P97 safely (fallback jika P97 belum ada)\n",
        "if \"P97\" in globals():\n",
        "    try:\n",
        "        P97_VAL = float(P97)\n",
        "    except Exception:\n",
        "        P97_VAL = _compute_rms_percentile(ENERGY_CURVE, q=97)\n",
        "else:\n",
        "    P97_VAL = _compute_rms_percentile(ENERGY_CURVE, q=97)\n",
        "\n",
        "ENABLE_PEAK_WINDOWS = (P97_VAL is not None)\n",
        "\n",
        "with StageTimer(6, \"Segment Proposal (Candidate Mining)\"):\n",
        "\n",
        "    CANDIDATES = []\n",
        "    cid = 0\n",
        "\n",
        "    # =====================================================\n",
        "    # A) SPEECH-BLOCK WINDOWS (sliding)\n",
        "    # =====================================================\n",
        "    speech_blocks = SPEECH_BLOCKS if \"SPEECH_BLOCKS\" in globals() else []\n",
        "    for bs, be in speech_blocks:\n",
        "        bs = float(bs); be = float(be)\n",
        "        dur = be - bs\n",
        "        if dur < MIN_CLIP_SEC:\n",
        "            continue\n",
        "\n",
        "        # window base: clamp ke MAX, tapi durasi end bisa fleksibel\n",
        "        win = min(MAX_DUR_SEC, max(MIN_DUR_SEC, dur))\n",
        "        step = 6.0\n",
        "        t = bs\n",
        "        while t + MIN_CLIP_SEC <= be:\n",
        "            hard_end = min(be, t + win)\n",
        "\n",
        "            if USE_FLEXIBLE_DUR:\n",
        "                end, end_reason = pick_flexible_end(\n",
        "                    start=t,\n",
        "                    hard_end=hard_end,\n",
        "                    silence_segments=SILENCE_SEGMENTS if \"SILENCE_SEGMENTS\" in globals() else [],\n",
        "                    speech_blocks=speech_blocks\n",
        "                )\n",
        "            else:\n",
        "                end, end_reason = hard_end, \"end:fixed\"\n",
        "\n",
        "            if (end - t) >= MIN_CLIP_SEC:\n",
        "                cid += 1\n",
        "                CANDIDATES.append({\n",
        "                    \"id\": f\"cand_{cid:04d}\",\n",
        "                    \"type\": \"speech_block\",\n",
        "                    \"start\": float(t),\n",
        "                    \"end\": float(end),\n",
        "                    \"duration\": float(end - t),\n",
        "                    \"end_reason\": end_reason,   # audit-friendly (non-core)\n",
        "                })\n",
        "            t += step\n",
        "\n",
        "    # =====================================================\n",
        "    # B) PEAK-CENTRIC WINDOWS (UPGRADE)\n",
        "    # =====================================================\n",
        "    if not ENABLE_PEAK_WINDOWS:\n",
        "        logger.warning(\"[STAGE 06] Peak detection disabled (P97 unavailable) ‚Äî skipping peak-centric mining\")\n",
        "    else:\n",
        "        peaks = [p for p in ENERGY_CURVE if float(p[\"rms\"]) >= float(P97_VAL)]\n",
        "        peaks = peaks[::max(1, len(peaks) // 200)] if peaks else []\n",
        "\n",
        "        for p in peaks:\n",
        "            peak_time = float(p[\"time\"])\n",
        "            ideal = 40.0\n",
        "            setup = 6.0\n",
        "            target_peak_offset = 15.0\n",
        "            min_peak_offset = 8.0\n",
        "            max_peak_offset = 25.0\n",
        "\n",
        "            wstart = peak_time - target_peak_offset\n",
        "            wend_hard = wstart + ideal\n",
        "\n",
        "            # clamp bounds\n",
        "            wstart = max(0.0, float(wstart))\n",
        "            wend_hard = min(float(ANALYZED_DURATION), float(wend_hard))\n",
        "\n",
        "            if wend_hard - wstart < MIN_CLIP_SEC:\n",
        "                continue\n",
        "\n",
        "            peak_abs, _ = get_peak_time(ENERGY_CURVE, wstart, wend_hard)\n",
        "            if peak_abs is None:\n",
        "                continue\n",
        "\n",
        "            peak_offset = peak_abs - wstart\n",
        "            if not (min_peak_offset <= peak_offset <= max_peak_offset):\n",
        "                continue\n",
        "            if peak_offset < (setup + 1.0):\n",
        "                continue\n",
        "\n",
        "            # flexible end seeking for peak windows too\n",
        "            hard_end = min(wstart + MAX_DUR_SEC, wend_hard)\n",
        "            if USE_FLEXIBLE_DUR:\n",
        "                wend, end_reason = pick_flexible_end(\n",
        "                    start=wstart,\n",
        "                    hard_end=hard_end,\n",
        "                    silence_segments=SILENCE_SEGMENTS if \"SILENCE_SEGMENTS\" in globals() else [],\n",
        "                    speech_blocks=speech_blocks\n",
        "                )\n",
        "            else:\n",
        "                wend, end_reason = hard_end, \"end:fixed\"\n",
        "\n",
        "            if wend - wstart < MIN_CLIP_SEC:\n",
        "                continue\n",
        "\n",
        "            cid += 1\n",
        "            CANDIDATES.append({\n",
        "                \"id\": f\"cand_{cid:04d}\",\n",
        "                \"type\": \"peak\",\n",
        "                \"start\": float(wstart),\n",
        "                \"end\": float(wend),\n",
        "                \"duration\": float(wend - wstart),\n",
        "                \"peak_time_abs\": float(peak_abs),\n",
        "                \"peak_offset_in_clip\": float(peak_offset),\n",
        "                \"end_reason\": end_reason,  # audit-friendly (non-core)\n",
        "            })\n",
        "\n",
        "    # =====================================================\n",
        "    # FINAL CLAMP & SAVE\n",
        "    # =====================================================\n",
        "    final = []\n",
        "    for c in CANDIDATES:\n",
        "        d = float(c[\"end\"] - c[\"start\"])\n",
        "        if d < MIN_CLIP_SEC:\n",
        "            continue\n",
        "        if d > MAX_DUR_SEC:\n",
        "            c[\"end\"] = float(c[\"start\"] + MAX_DUR_SEC)\n",
        "            c[\"duration\"] = float(c[\"end\"] - c[\"start\"])\n",
        "            c[\"end_reason\"] = (c.get(\"end_reason\",\"\") + \"|clamp:max\").strip(\"|\")\n",
        "        final.append(c)\n",
        "\n",
        "    CANDIDATES = sorted(final, key=lambda x: (x[\"start\"], x[\"end\"], x[\"id\"]))\n",
        "    write_json(ART_DIR / \"candidates.json\", CANDIDATES)\n",
        "\n",
        "    logger.info(f\"Candidates: {len(CANDIDATES)}\")\n",
        "    log_flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51dae189-29ae-472f-988b-e925335cbe3d",
      "metadata": {},
      "source": [
        "## üß™ Stage 7: Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02eaf98-33e4-4ec5-98fa-ea18efdc562b",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-30T12:04:50.439182Z",
          "iopub.status.idle": "2026-01-30T12:04:50.439507Z",
          "shell.execute_reply": "2026-01-30T12:04:50.439376Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.439358Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# Stage 7: Feature Extraction\n",
        "# =========================\n",
        "import numpy as np\n",
        "def percentile_value(sorted_vals, q):\n",
        "    if not sorted_vals:\n",
        "        return 0.0\n",
        "    if q <= 0:\n",
        "        return float(sorted_vals[0])\n",
        "    if q >= 1:\n",
        "        return float(sorted_vals[-1])\n",
        "    idx = int(round(q * (len(sorted_vals) - 1)))\n",
        "    return float(sorted_vals[max(0, min(len(sorted_vals)-1, idx))])\n",
        "\n",
        "def window_points(energy_curve, start, end):\n",
        "    return [e for e in energy_curve if start <= e[\"time\"] <= end]\n",
        "\n",
        "def clamp01(x): \n",
        "    return max(0.0, min(1.0, float(x)))\n",
        "\n",
        "def compute_features(candidate: Dict[str,Any]) -> Dict[str,Any]:\n",
        "    s = candidate[\"start\"]\n",
        "    e = candidate[\"end\"]\n",
        "    dur = e - s\n",
        "    pts = window_points(ENERGY_CURVE, s, e)\n",
        "    if not pts:\n",
        "        pts = [{\"time\": s, \"rms\": 0.0}]\n",
        "    rms = np.array([p[\"rms\"] for p in pts], dtype=np.float32)\n",
        "    mean = float(rms.mean())\n",
        "    peak = float(rms.max())\n",
        "    std = float(rms.std())\n",
        "    ptm = float(peak / (mean + 1e-9))\n",
        "\n",
        "    # hook energy first 0‚Äì5s\n",
        "    hook_pts = window_points(ENERGY_CURVE, s, min(e, s + HOOK_WINDOW_SEC))\n",
        "    hook_rms = np.array([p[\"rms\"] for p in hook_pts], dtype=np.float32) if hook_pts else np.array([0.0],dtype=np.float32)\n",
        "    hook_energy = float(hook_rms.mean())\n",
        "\n",
        "    # early/late energy (fallback arc)\n",
        "    early_pts = window_points(ENERGY_CURVE, s, min(e, s + dur*0.25))\n",
        "    late_pts  = window_points(ENERGY_CURVE, max(s, e - dur*0.25), e)\n",
        "    early_energy = float(np.mean([p[\"rms\"] for p in early_pts])) if early_pts else mean\n",
        "    late_energy  = float(np.mean([p[\"rms\"] for p in late_pts])) if late_pts else mean\n",
        "\n",
        "    # peak time & offset\n",
        "    peak_pt = max(pts, key=lambda x: x[\"rms\"])\n",
        "    peak_time_abs = float(peak_pt[\"time\"])\n",
        "    peak_offset_in_clip = float(peak_time_abs - s)\n",
        "\n",
        "    # spike rate: local peaks above global P90\n",
        "    all_rms_sorted = sorted([p[\"rms\"] for p in ENERGY_CURVE] or [0.0])\n",
        "    P90 = percentile_value(all_rms_sorted, 0.90)\n",
        "    spikes = 0\n",
        "    for i in range(1, len(pts)-1):\n",
        "        a,b,c = pts[i-1], pts[i], pts[i+1]\n",
        "        if b[\"rms\"] >= P90 and b[\"rms\"] >= a[\"rms\"] and b[\"rms\"] >= c[\"rms\"]:\n",
        "            spikes += 1\n",
        "    spike_rate = float(spikes / (dur + 1e-6))\n",
        "\n",
        "    # silence ratio within candidate\n",
        "    sil = 0.0\n",
        "    for (ss,se) in SILENCE_SEGMENTS:\n",
        "        inter = max(0.0, min(e,se) - max(s,ss))\n",
        "        sil += inter\n",
        "    silence_ratio = float(sil / (dur + 1e-6))\n",
        "\n",
        "    # distance to nearest shot cut\n",
        "    if SHOT_CUTS:\n",
        "        near_cut = float(min(abs(c - s) for c in SHOT_CUTS + [s]) if SHOT_CUTS else 9999.0)\n",
        "        near_cut_end = float(min(abs(c - e) for c in SHOT_CUTS + [e]) if SHOT_CUTS else 9999.0)\n",
        "        near_cut_dist = float(min(near_cut, near_cut_end))\n",
        "    else:\n",
        "        near_cut_dist = 9999.0\n",
        "\n",
        "    return {\n",
        "        \"mean_energy\": mean,\n",
        "        \"peak_energy\": peak,\n",
        "        \"energy_stddev\": std,\n",
        "        \"peak_to_mean\": ptm,\n",
        "        \"hook_energy\": hook_energy,\n",
        "        \"early_energy\": early_energy,\n",
        "        \"late_energy\": late_energy,\n",
        "        \"peak_time_abs\": peak_time_abs,\n",
        "        \"peak_offset_in_clip\": peak_offset_in_clip,\n",
        "        \"spike_rate\": spike_rate,\n",
        "        \"silence_ratio\": silence_ratio,\n",
        "        \"near_cut_dist\": near_cut_dist,\n",
        "        # ASR-dependent placeholders (filled later)\n",
        "        \"words_per_sec\": 2.0,\n",
        "        \"trigger_count\": 0,\n",
        "        \"markers_abs\": [],\n",
        "        # for scoring logic\n",
        "        \"start_abs_for_scoring\": s,\n",
        "        \"end_abs_for_scoring\": e,\n",
        "    }\n",
        "\n",
        "with StageTimer(7, \"Feature Extraction\"):\n",
        "    for c in CANDIDATES:\n",
        "        c[\"features\"] = compute_features(c)\n",
        "    logger.info(\"Features computed for all candidates.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4647c5a3-0ca4-4bc7-8935-1c5ecba35f71",
      "metadata": {},
      "source": [
        "## üó£Ô∏è Stage 8: ASR (QUALITY Mode + Cache + Heartbeat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1433cee2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Stage 8: ASR (Top-N per bucket + Cache + Fail-safe)\n",
        "# =========================\n",
        "\n",
        "TIME_BUCKETS = 5\n",
        "ASR_TOPN_PER_BUCKET = int(os.getenv(\"ASR_TOPN_PER_BUCKET\", \"4\"))\n",
        "ASR_MODEL_NAME = os.getenv(\"ASR_MODEL_NAME\", \"tiny\")\n",
        "ASR_BEAM_SIZE = int(os.getenv(\"ASR_BEAM_SIZE\", \"1\"))\n",
        "ASR_LIGHT_MODE = os.getenv(\"ASR_LIGHT_MODE\", \"1\") == \"1\"\n",
        "ASR_LIGHT_SEC = float(os.getenv(\"ASR_LIGHT_SEC\", \"10.0\"))\n",
        "ASR_LIGHT_OFFSET = float(os.getenv(\"ASR_LIGHT_OFFSET\", \"2.0\"))\n",
        "\n",
        "\n",
        "def split_ranges(start, end, max_len=MAX_ASR_BLOCK_SEC, overlap=ASR_BLOCK_OVERLAP_SEC):\n",
        "    ranges = []\n",
        "    t = start\n",
        "    while t < end - 0.1:\n",
        "        t2 = min(end, t + max_len)\n",
        "        ranges.append((t, t2))\n",
        "        if t2 >= end:\n",
        "            break\n",
        "        t = t2 - overlap if overlap > 0 else t2\n",
        "    return ranges\n",
        "\n",
        "\n",
        "def safe_unlink(path: Path):\n",
        "    try:\n",
        "        if path.exists():\n",
        "            path.unlink()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "def _bucket_index(t):\n",
        "    if ANALYZED_DURATION <= 0:\n",
        "        return 0\n",
        "    idx = int((t / ANALYZED_DURATION) * TIME_BUCKETS)\n",
        "    if idx < 0:\n",
        "        idx = 0\n",
        "    if idx >= TIME_BUCKETS:\n",
        "        idx = TIME_BUCKETS - 1\n",
        "    return idx\n",
        "\n",
        "\n",
        "def _percentile_rank(values, x):\n",
        "    if not values:\n",
        "        return 0.0\n",
        "    vs = sorted(values)\n",
        "    lo, hi = 0, len(vs)\n",
        "    while lo < hi:\n",
        "        mid = (lo + hi) // 2\n",
        "        if vs[mid] <= x:\n",
        "            lo = mid + 1\n",
        "        else:\n",
        "            hi = mid\n",
        "    return lo / len(vs)\n",
        "\n",
        "\n",
        "def _pre_score(c, hook_vals, ptm_vals, spk_vals, sil_vals):\n",
        "    f = c.get(\"features\", {})\n",
        "    p_hook = _percentile_rank(hook_vals, f.get(\"hook_energy\", 0.0))\n",
        "    p_ptm = _percentile_rank(ptm_vals, f.get(\"peak_to_mean\", 0.0))\n",
        "    p_spk = _percentile_rank(spk_vals, f.get(\"spike_rate\", 0.0))\n",
        "    p_sil = _percentile_rank(sil_vals, f.get(\"silence_ratio\", 0.0))\n",
        "    return (0.40 * p_hook) + (0.30 * p_ptm) + (0.20 * p_spk) - (0.20 * p_sil)\n",
        "\n",
        "\n",
        "def _light_window(start, end):\n",
        "    dur = max(0.0, end - start)\n",
        "    if dur <= ASR_LIGHT_SEC:\n",
        "        return start, end\n",
        "    s = min(end - 0.1, start + ASR_LIGHT_OFFSET)\n",
        "    e = min(end, s + ASR_LIGHT_SEC)\n",
        "    if e - s < 4.0:\n",
        "        # fallback to center window\n",
        "        mid = start + dur * 0.5\n",
        "        s = max(start, mid - ASR_LIGHT_SEC * 0.5)\n",
        "        e = min(end, s + ASR_LIGHT_SEC)\n",
        "    return s, e\n",
        "\n",
        "\n",
        "with StageTimer(8, \"ASR (top-N per bucket, cache, fail-safe)\"):\n",
        "    TRANSCRIPTS = {}\n",
        "    transcript_cache_path = ART_DIR / \"transcript.json\"\n",
        "\n",
        "    # Load cache\n",
        "    if transcript_cache_path.exists():\n",
        "        try:\n",
        "            TRANSCRIPTS = read_json(transcript_cache_path) or {}\n",
        "            logger.info(f\"Loaded transcript cache: {transcript_cache_path} ({len(TRANSCRIPTS)} items)\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Transcript cache load failed; starting empty. ({e})\")\n",
        "            TRANSCRIPTS = {}\n",
        "\n",
        "    # Prepare ASR model\n",
        "    ASR_AVAILABLE = False\n",
        "    model = None\n",
        "    if ASR_ENABLED:\n",
        "        try:\n",
        "            try:\n",
        "                from faster_whisper import WhisperModel\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"faster-whisper not available ({e}). Trying to install...\")\n",
        "                subprocess.run([\"pip\", \"-q\", \"install\", \"faster-whisper\"], check=True)\n",
        "                from faster_whisper import WhisperModel\n",
        "\n",
        "            model = WhisperModel(ASR_MODEL_NAME, device=\"cpu\", compute_type=\"int8\")\n",
        "            ASR_AVAILABLE = True\n",
        "            logger.info(f\"ASR model ready: faster-whisper {ASR_MODEL_NAME} (cpu int8)\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"ASR unavailable; continuing without transcript. ({e})\")\n",
        "            ASR_AVAILABLE = False\n",
        "\n",
        "    def transcribe_candidate_abs(candidate: Dict[str,Any], mode: str = \"full\") -> Dict[str,Any]:\n",
        "        if not ASR_AVAILABLE or model is None:\n",
        "            return {\"text\":\"\", \"words\":[], \"markers_abs\":[], \"words_per_sec\":0.0, \"trigger_count\":0, \"word_count\":0, \"mode\": mode}\n",
        "\n",
        "        cid = candidate[\"id\"]\n",
        "        start = float(candidate[\"start\"])\n",
        "        end = float(candidate[\"end\"])\n",
        "\n",
        "        if mode == \"light\":\n",
        "            ls, le = _light_window(start, end)\n",
        "            ranges = split_ranges(ls, le)\n",
        "        else:\n",
        "            ranges = split_ranges(start, end)\n",
        "\n",
        "        all_words = []\n",
        "        full_text = []\n",
        "        markers_abs = []\n",
        "\n",
        "        for bi, (bs, be) in enumerate(ranges, 1):\n",
        "            block_wav = CACHE_DIR / f\"asrblock_{cid}_{bi:02d}.wav\"\n",
        "            subprocess.run([\n",
        "                FFMPEG_BIN, \"-y\", \"-loglevel\", \"error\",\n",
        "                \"-ss\", str(bs), \"-t\", str(be - bs),\n",
        "                \"-i\", str(ART_DIR / \"audio.wav\"),\n",
        "                \"-ac\", \"1\", \"-ar\", \"16000\",\n",
        "                str(block_wav)\n",
        "            ], check=True)\n",
        "\n",
        "            t0 = time.monotonic()\n",
        "            logger.info(f\"ASR [{cid}] block {bi}/{len(ranges)} START {bs:.2f}-{be:.2f} (mode={mode})\")\n",
        "            log_flush()\n",
        "\n",
        "            segments, info = model.transcribe(str(block_wav), language=ASR_LANGUAGE, beam_size=ASR_BEAM_SIZE)\n",
        "            for seg in segments:\n",
        "                if seg.text:\n",
        "                    full_text.append(seg.text)\n",
        "                for w in (seg.words or []):\n",
        "                    all_words.append({\n",
        "                        \"word\": w.word,\n",
        "                        \"start\": float(w.start + bs),\n",
        "                        \"end\": float(w.end + bs)\n",
        "                    })\n",
        "\n",
        "            dt = time.monotonic() - t0\n",
        "            logger.info(f\"ASR [{cid}] block {bi} DONE in {dt:.2f}s\")\n",
        "            log_flush()\n",
        "\n",
        "            safe_unlink(block_wav)\n",
        "\n",
        "        # markers from trigger words\n",
        "        trigger_set = set([t.lower() for t in (TRIGGER_WORDS if \"TRIGGER_WORDS\" in globals() else [])])\n",
        "        for w in all_words:\n",
        "            tok = (w.get(\"word\") or \"\").strip().lower()\n",
        "            if tok in trigger_set:\n",
        "                markers_abs.append(float(w.get(\"start\", 0.0)))\n",
        "\n",
        "        text = \" \".join(full_text).strip()\n",
        "        word_count = len(all_words)\n",
        "        dur = max(0.1, float(end - start)) if mode == \"full\" else max(0.1, float(ranges[-1][1] - ranges[0][0]))\n",
        "        wps = float(word_count / dur)\n",
        "        trigger_count = len(markers_abs)\n",
        "\n",
        "        return {\n",
        "            \"text\": text,\n",
        "            \"words\": all_words,\n",
        "            \"markers_abs\": markers_abs,\n",
        "            \"words_per_sec\": wps,\n",
        "            \"trigger_count\": trigger_count,\n",
        "            \"word_count\": word_count,\n",
        "            \"mode\": mode,\n",
        "        }\n",
        "\n",
        "    # Build per-bucket pools and pick top-N\n",
        "    hook_vals = [c.get(\"features\", {}).get(\"hook_energy\", 0.0) for c in CANDIDATES]\n",
        "    ptm_vals = [c.get(\"features\", {}).get(\"peak_to_mean\", 0.0) for c in CANDIDATES]\n",
        "    spk_vals = [c.get(\"features\", {}).get(\"spike_rate\", 0.0) for c in CANDIDATES]\n",
        "    sil_vals = [c.get(\"features\", {}).get(\"silence_ratio\", 0.0) for c in CANDIDATES]\n",
        "\n",
        "    bucket_map = {b: [] for b in range(TIME_BUCKETS)}\n",
        "    for c in CANDIDATES:\n",
        "        b = _bucket_index(float(c.get(\"start\", 0.0)))\n",
        "        bucket_map[b].append(c)\n",
        "\n",
        "    top_for_asr = []\n",
        "    for b, arr in bucket_map.items():\n",
        "        arr_sorted = sorted(arr, key=lambda c: _pre_score(c, hook_vals, ptm_vals, spk_vals, sil_vals), reverse=True)\n",
        "        top_for_asr.extend(arr_sorted[:ASR_TOPN_PER_BUCKET])\n",
        "\n",
        "    # Transcribe top-N per bucket\n",
        "    if not ASR_AVAILABLE:\n",
        "        logger.warning(\"SEMANTIC_FALLBACK: ASR unavailable\")\n",
        "    else:\n",
        "        logger.info(f\"ASR top-N per bucket: {len(top_for_asr)} candidates (mode={'light' if ASR_LIGHT_MODE else 'full'})\")\n",
        "\n",
        "    for c in top_for_asr:\n",
        "        cid = c[\"id\"]\n",
        "        existing = TRANSCRIPTS.get(cid, {}) if isinstance(TRANSCRIPTS, dict) else {}\n",
        "        if existing.get(\"text\") and existing.get(\"mode\") == \"full\":\n",
        "            out = existing\n",
        "        else:\n",
        "            try:\n",
        "                mode = \"light\" if ASR_LIGHT_MODE else \"full\"\n",
        "                out = transcribe_candidate_abs(c, mode=mode)\n",
        "                TRANSCRIPTS[cid] = out\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"ASR failed for {cid}: {e}\")\n",
        "                out = {\"text\":\"\", \"words\":[], \"markers_abs\":[], \"words_per_sec\":0.0, \"trigger_count\":0, \"word_count\":0, \"mode\": \"light\"}\n",
        "                TRANSCRIPTS[cid] = out\n",
        "\n",
        "        # Enrich candidate features from transcript\n",
        "        f = c.get(\"features\", {})\n",
        "        f[\"words_per_sec\"] = float(out.get(\"words_per_sec\", 0.0))\n",
        "        f[\"trigger_count\"] = int(out.get(\"trigger_count\", 0))\n",
        "        f[\"markers_abs\"] = list(out.get(\"markers_abs\", []))\n",
        "        f[\"word_count\"] = int(out.get(\"word_count\", 0))\n",
        "        f[\"has_text\"] = True if (out.get(\"text\") or \"\").strip() else False\n",
        "        c[\"features\"] = f\n",
        "\n",
        "    # Save transcript cache\n",
        "    try:\n",
        "        write_json(transcript_cache_path, TRANSCRIPTS)\n",
        "        logger.info(f\"Saved transcript cache (entries={len(TRANSCRIPTS)})\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Failed to save transcript cache: {e}\")\n",
        "\n",
        "    # Expose globals\n",
        "    globals()[\"TRANSCRIPTS\"] = TRANSCRIPTS\n",
        "    globals()[\"ASR_AVAILABLE\"] = ASR_AVAILABLE\n",
        "    globals()[\"transcribe_candidate_abs\"] = transcribe_candidate_abs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5599424-cd43-4480-90eb-2cecaf47021c",
      "metadata": {},
      "source": [
        "## üßÆ Stage 9: Scoring (Audit-able, Percentile-Based)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8db95d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Stage 9: Scoring (Bucket-normalized, semantic-aware)\n",
        "# =========================\n",
        "\n",
        "TIME_BUCKETS = 5\n",
        "\n",
        "\n",
        "def token_set(text: str):\n",
        "    return set(re.findall(r\"[a-zA-Z0-9]+\", (text or \"\").lower()))\n",
        "\n",
        "\n",
        "def clip100(x: float) -> float:\n",
        "    return float(max(0.0, min(100.0, x)))\n",
        "\n",
        "\n",
        "def percentile_rank(values, x):\n",
        "    if not values:\n",
        "        return 0.0\n",
        "    vs = sorted(values)\n",
        "    lo, hi = 0, len(vs)\n",
        "    while lo < hi:\n",
        "        mid = (lo + hi) // 2\n",
        "        if vs[mid] <= x:\n",
        "            lo = mid + 1\n",
        "        else:\n",
        "            hi = mid\n",
        "    return lo / len(vs)\n",
        "\n",
        "\n",
        "def bucket_index(t):\n",
        "    if ANALYZED_DURATION <= 0:\n",
        "        return 0\n",
        "    idx = int((t / ANALYZED_DURATION) * TIME_BUCKETS)\n",
        "    if idx < 0:\n",
        "        idx = 0\n",
        "    if idx >= TIME_BUCKETS:\n",
        "        idx = TIME_BUCKETS - 1\n",
        "    return idx\n",
        "\n",
        "\n",
        "def finishability_score(end_t: float) -> float:\n",
        "    if \"SILENCE_SEGMENTS\" in globals():\n",
        "        for s, e in (SILENCE_SEGMENTS or []):\n",
        "            s = float(s)\n",
        "            if end_t <= s <= (end_t + 1.6):\n",
        "                return 100.0\n",
        "    if \"SPEECH_BLOCKS\" in globals():\n",
        "        best = None\n",
        "        for s, e in (SPEECH_BLOCKS or []):\n",
        "            e = float(e)\n",
        "            if e >= end_t:\n",
        "                d = e - end_t\n",
        "                if best is None or d < best:\n",
        "                    best = d\n",
        "        if best is not None:\n",
        "            if best <= 1.0:\n",
        "                return 85.0\n",
        "            if best <= 2.5:\n",
        "                return 55.0\n",
        "    return 20.0\n",
        "\n",
        "\n",
        "with StageTimer(9, \"Scoring (bucket-normalized)\"):\n",
        "    # Build bucket pools\n",
        "    buckets = {b: [] for b in range(TIME_BUCKETS)}\n",
        "    for c in CANDIDATES:\n",
        "        b = bucket_index(float(c.get(\"start\", 0.0)))\n",
        "        buckets[b].append(c)\n",
        "\n",
        "    # Build per-bucket distributions\n",
        "    def build_vals(key, transform=lambda x: x):\n",
        "        vals = {b: [] for b in buckets}\n",
        "        for b, arr in buckets.items():\n",
        "            for c in arr:\n",
        "                v = transform(c.get(\"features\", {}).get(key, 0.0))\n",
        "                vals[b].append(float(v))\n",
        "        return vals\n",
        "\n",
        "    hook_vals = build_vals(\"hook_energy\")\n",
        "    ptm_vals = build_vals(\"peak_to_mean\")\n",
        "    std_vals = build_vals(\"energy_stddev\")\n",
        "    spk_vals = build_vals(\"spike_rate\")\n",
        "    wps_vals = build_vals(\"words_per_sec\")\n",
        "    sil_vals = build_vals(\"silence_ratio\")\n",
        "    trig_vals = build_vals(\"trigger_count\")\n",
        "\n",
        "    # Novelty per bucket\n",
        "    novelty_vals = {b: [] for b in buckets}\n",
        "    for b, arr in buckets.items():\n",
        "        seen = []\n",
        "        arr_sorted = sorted(arr, key=lambda c: -c.get(\"features\", {}).get(\"hook_energy\", 0.0))\n",
        "        for c in arr_sorted:\n",
        "            txt = \"\"\n",
        "            if \"TRANSCRIPTS\" in globals() and isinstance(TRANSCRIPTS, dict):\n",
        "                txt = TRANSCRIPTS.get(c.get(\"id\"), {}).get(\"text\", \"\")\n",
        "            tokens = token_set(txt)\n",
        "            max_sim = 0.0\n",
        "            for prev in seen[:8]:\n",
        "                if tokens or prev:\n",
        "                    max_sim = max(max_sim, len(tokens & prev) / max(1, len(tokens | prev)))\n",
        "            novelty = clip100((1.0 - max_sim) * 100) if tokens else 50.0\n",
        "            c.setdefault(\"scores\", {})\n",
        "            c[\"scores\"][\"novelty\"] = novelty\n",
        "            novelty_vals[b].append(float(novelty))\n",
        "            seen.append(tokens)\n",
        "\n",
        "    # Semantic availability\n",
        "    SEMANTIC_AVAILABLE = False\n",
        "    if \"TRANSCRIPTS\" in globals() and isinstance(TRANSCRIPTS, dict):\n",
        "        SEMANTIC_AVAILABLE = any((TRANSCRIPTS.get(c.get(\"id\"), {}).get(\"text\", \"\") or \"\").strip() for c in CANDIDATES)\n",
        "\n",
        "    if not SEMANTIC_AVAILABLE:\n",
        "        logger.warning(\"SEMANTIC_FALLBACK: no transcripts for candidates\")\n",
        "\n",
        "    # Scoring per candidate\n",
        "    for c in CANDIDATES:\n",
        "        f = c.get(\"features\", {})\n",
        "        b = bucket_index(float(c.get(\"start\", 0.0)))\n",
        "\n",
        "        p_hook = percentile_rank(hook_vals[b], f.get(\"hook_energy\", 0.0))\n",
        "        p_ptm = percentile_rank(ptm_vals[b], f.get(\"peak_to_mean\", 0.0))\n",
        "        p_std = percentile_rank(std_vals[b], f.get(\"energy_stddev\", 0.0))\n",
        "        p_spk = percentile_rank(spk_vals[b], f.get(\"spike_rate\", 0.0))\n",
        "        p_wps = percentile_rank(wps_vals[b], f.get(\"words_per_sec\", 0.0))\n",
        "        p_trig = percentile_rank(trig_vals[b], f.get(\"trigger_count\", 0.0))\n",
        "        p_sil = percentile_rank(sil_vals[b], f.get(\"silence_ratio\", 0.0))\n",
        "        p_nov = percentile_rank(novelty_vals[b], c.get(\"scores\", {}).get(\"novelty\", 50.0))\n",
        "\n",
        "        # Meaning score\n",
        "        if SEMANTIC_AVAILABLE and f.get(\"has_text\", False):\n",
        "            meaning = clip100(100 * (0.45 * p_trig + 0.35 * p_wps + 0.20 * p_nov))\n",
        "            semantic_mode = \"semantic\"\n",
        "        elif SEMANTIC_AVAILABLE:\n",
        "            meaning = 20.0\n",
        "            semantic_mode = \"no_text\"\n",
        "        else:\n",
        "            meaning = clip100(100 * (0.60 * p_hook + 0.40 * p_spk))\n",
        "            semantic_mode = \"fallback\"\n",
        "\n",
        "        # Hook score\n",
        "        early_marker = 0.0\n",
        "        start = f.get(\"start_abs_for_scoring\")\n",
        "        if start is not None:\n",
        "            ms = f.get(\"markers_abs\", []) or []\n",
        "            early_marker = 1.0 if any(start <= m <= start + HOOK_WINDOW_SEC for m in ms) else 0.0\n",
        "        hook = clip100(100 * (0.60 * p_hook + 0.25 * early_marker + 0.15 * p_wps))\n",
        "\n",
        "        # Energy score (not dominant)\n",
        "        energy = clip100(100 * (0.40 * p_ptm + 0.35 * p_std + 0.25 * p_spk))\n",
        "\n",
        "        # Clarity score\n",
        "        fin = finishability_score(float(c.get(\"end\", 0.0)))\n",
        "        fin_n = fin / 100.0\n",
        "        clarity = clip100(100 * (0.55 * fin_n + 0.30 * (1.0 - p_sil) + 0.15 * p_wps))\n",
        "\n",
        "        if SEMANTIC_AVAILABLE:\n",
        "            viral = (0.35 * meaning) + (0.25 * hook) + (0.20 * clarity) + (0.20 * energy)\n",
        "        else:\n",
        "            viral = (0.20 * meaning) + (0.30 * hook) + (0.25 * clarity) + (0.25 * energy)\n",
        "\n",
        "        c[\"scores\"] = {\n",
        "            \"meaning\": meaning,\n",
        "            \"hook\": hook,\n",
        "            \"clarity\": clarity,\n",
        "            \"energy\": energy,\n",
        "            \"novelty\": c.get(\"scores\", {}).get(\"novelty\", 50.0),\n",
        "            \"finishability\": fin,\n",
        "            \"viral_score\": clip100(viral),\n",
        "            \"semantic_mode\": semantic_mode,\n",
        "        }\n",
        "\n",
        "    # Editorial reason (audit)\n",
        "    def editorial_reason(c):\n",
        "        s = c.get(\"scores\", {})\n",
        "        return [\n",
        "            f\"Meaning {s.get('meaning',0):.1f} ({s.get('semantic_mode','')})\",\n",
        "            f\"Hook {s.get('hook',0):.1f}\",\n",
        "            f\"Clarity {s.get('clarity',0):.1f}\",\n",
        "            f\"Energy {s.get('energy',0):.1f}\",\n",
        "            f\"Novelty {s.get('novelty',0):.1f}\",\n",
        "        ]\n",
        "\n",
        "    for c in CANDIDATES:\n",
        "        c[\"editorial_reason\"] = editorial_reason(c)\n",
        "\n",
        "    # Observability: write full ranking.csv (all candidates)\n",
        "    ranking_csv = OUT_DIR / \"ranking.csv\"\n",
        "    with open(ranking_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        fieldnames = [\"id\",\"start\",\"end\",\"duration\",\"bucket\",\"meaning\",\"hook\",\"clarity\",\"energy\",\"novelty\",\"finishability\",\"viral_score\",\"semantic_mode\"]\n",
        "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        w.writeheader()\n",
        "        for c in sorted(CANDIDATES, key=lambda x: (-x.get(\"scores\", {}).get(\"viral_score\", 0.0), x.get(\"start\", 0.0))):\n",
        "            s = c.get(\"scores\", {})\n",
        "            w.writerow({\n",
        "                \"id\": c.get(\"id\"),\n",
        "                \"start\": float(c.get(\"start\", 0.0)),\n",
        "                \"end\": float(c.get(\"end\", 0.0)),\n",
        "                \"duration\": float(c.get(\"duration\", 0.0)),\n",
        "                \"bucket\": bucket_index(float(c.get(\"start\", 0.0))),\n",
        "                \"meaning\": float(s.get(\"meaning\", 0.0)),\n",
        "                \"hook\": float(s.get(\"hook\", 0.0)),\n",
        "                \"clarity\": float(s.get(\"clarity\", 0.0)),\n",
        "                \"energy\": float(s.get(\"energy\", 0.0)),\n",
        "                \"novelty\": float(s.get(\"novelty\", 0.0)),\n",
        "                \"finishability\": float(s.get(\"finishability\", 0.0)),\n",
        "                \"viral_score\": float(s.get(\"viral_score\", 0.0)),\n",
        "                \"semantic_mode\": s.get(\"semantic_mode\", \"\")\n",
        "            })\n",
        "\n",
        "    logger.info(f\"Wrote ranking.csv (all candidates): {ranking_csv}\")\n",
        "    log_flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20068fbe-131b-4285-a2a5-57590234508b",
      "metadata": {},
      "source": [
        "## üìä Log Rapi: Tabel Ranking (Bahasa Indonesia)\n",
        "\n",
        "Cell ini membuat output seperti tabel (mirip screenshot):\n",
        "- Menyimpan `/kaggle/working/output/ranking.csv`\n",
        "- Menampilkan Top 12 preview\n",
        "- Kolom pakai Bahasa Indonesia\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5091e179-dbe6-4b3e-b589-62cfd734e4d9",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-30T12:04:50.446544Z",
          "iopub.status.idle": "2026-01-30T12:04:50.446912Z",
          "shell.execute_reply": "2026-01-30T12:04:50.446779Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.446760Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Ranking Table (Rapi, Bahasa Indonesia)\n",
        "# =========================\n",
        "import pandas as pd\n",
        "\n",
        "ranked = sorted(CANDIDATES, key=lambda x: (-x[\"scores\"][\"viral_score\"], x[\"start\"], x[\"id\"]))\n",
        "\n",
        "rows = []\n",
        "for i, c in enumerate(ranked, 1):\n",
        "    f = c.get(\"features\", {})\n",
        "    s = c.get(\"scores\", {})\n",
        "    rows.append({\n",
        "        \"peringkat\": i,\n",
        "        \"id_segmen\": c.get(\"id\"),\n",
        "        \"tipe_segmen\": c.get(\"type\", \"\"),\n",
        "        \"mulai_detik\": round(float(c.get(\"start\", 0.0)), 3),\n",
        "        \"akhir_detik\": round(float(c.get(\"end\", 0.0)), 3),\n",
        "        \"durasi_detik\": round(float(c.get(\"duration\", 0.0)), 3),\n",
        "\n",
        "        \"skor_viral_total\": round(float(s.get(\"viral_score\", 0.0)), 3),\n",
        "\n",
        "        \"skor_hook\": round(float(s.get(\"hook\", 0.0)), 3),\n",
        "        \"skor_emosi\": round(float(s.get(\"emotion\", 0.0)), 3),\n",
        "        \"skor_kepadatan_info\": round(float(s.get(\"density\", 0.0)), 3),\n",
        "        \"skor_alur_cerita\": round(float(s.get(\"arc\", 0.0)), 3),\n",
        "        \"skor_keamanan_audio\": round(float(s.get(\"safety\", 0.0)), 3),\n",
        "        \"skor_posisi_puncak\": round(float(s.get(\"peak_placement\", 0.0)), 3),\n",
        "        \"skor_kebaruan\": round(float(s.get(\"novelty\", 0.0)), 3),\n",
        "\n",
        "        # fitur mentah untuk audit (opsional)\n",
        "        \"energi_hook\": round(float(f.get(\"hook_energy\", 0.0)), 6),\n",
        "        \"tingkat_chaos\": round(float(f.get(\"spike_rate\", 0.0)), 6),\n",
        "        \"rasio_puncak_vs_rata2\": round(float(f.get(\"peak_to_mean\", 0.0)), 6),\n",
        "        \"kata_per_detik\": round(float(f.get(\"words_per_sec\", 0.0)), 6),\n",
        "        \"rasio_diam\": round(float(f.get(\"silence_ratio\", 0.0)), 6),\n",
        "        \"jarak_dari_cut_kamera\": round(float(f.get(\"near_cut_dist\", 9999.0)), 3),\n",
        "\n",
        "        \"alasan_editorial\": (c.get(\"editorial_reason\", [\"\"])[0] if c.get(\"editorial_reason\") else \"\")\n",
        "    })\n",
        "\n",
        "df_ranking = pd.DataFrame(rows)\n",
        "\n",
        "# sesuai screenshot: simpan di /kaggle/working/output/\n",
        "rank_csv = OUT_DIR / \"ranking.csv\"\n",
        "df_ranking.to_csv(rank_csv, index=False, encoding=\"utf-8\")\n",
        "logger.info(f\"‚úÖ Ranking saved: {rank_csv}\")\n",
        "\n",
        "TOP_N = 12\n",
        "print(f\"Top {TOP_N} preview:\")\n",
        "display(df_ranking.head(TOP_N))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e23397-3d35-40a1-9048-3f86e4b5a65a",
      "metadata": {},
      "source": [
        "## üß≠ Stage 10: Deterministic Selection + Diversity + Timeline Sanity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13546767",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Stage 10: Selection (bucket quota + fairness)\n",
        "# =========================\n",
        "\n",
        "TIME_BUCKETS = 5\n",
        "\n",
        "\n",
        "def overlaps(a_start, a_end, b_start, b_end, gap=MIN_GAP_SEC):\n",
        "    return not (a_end + gap <= b_start or b_end + gap <= a_start)\n",
        "\n",
        "\n",
        "def bucket_index(t):\n",
        "    if ANALYZED_DURATION <= 0:\n",
        "        return 0\n",
        "    idx = int((t / ANALYZED_DURATION) * TIME_BUCKETS)\n",
        "    if idx < 0:\n",
        "        idx = 0\n",
        "    if idx >= TIME_BUCKETS:\n",
        "        idx = TIME_BUCKETS - 1\n",
        "    return idx\n",
        "\n",
        "\n",
        "def percentile(values, q):\n",
        "    if not values:\n",
        "        return 0.0\n",
        "    vs = sorted(values)\n",
        "    k = int(round((q / 100.0) * (len(vs) - 1)))\n",
        "    return float(vs[max(0, min(len(vs)-1, k))])\n",
        "\n",
        "\n",
        "with StageTimer(10, \"Selection (bucket quota + fairness)\"):\n",
        "    selection_audit = []\n",
        "\n",
        "    # Bucket pools\n",
        "    buckets = {b: [] for b in range(TIME_BUCKETS)}\n",
        "    for c in CANDIDATES:\n",
        "        b = bucket_index(float(c.get(\"start\", 0.0)))\n",
        "        buckets[b].append(c)\n",
        "\n",
        "    # Sort within buckets by viral_score desc\n",
        "    for b in buckets:\n",
        "        buckets[b].sort(key=lambda c: (-c.get(\"scores\", {}).get(\"viral_score\", 0.0), c.get(\"start\", 0.0), c.get(\"id\", \"\")))\n",
        "\n",
        "    # Per-bucket thresholds (no global absolute)\n",
        "    bucket_stats = {}\n",
        "    meaning_min = {}\n",
        "    score_min = {}\n",
        "    for b, arr in buckets.items():\n",
        "        meaning_vals = [c.get(\"scores\", {}).get(\"meaning\", 0.0) for c in arr]\n",
        "        score_vals = [c.get(\"scores\", {}).get(\"viral_score\", 0.0) for c in arr]\n",
        "        meaning_min[b] = percentile(meaning_vals, 35) if meaning_vals else 0.0\n",
        "        score_min[b] = percentile(score_vals, 40) if score_vals else 0.0\n",
        "        bucket_stats[b] = {\n",
        "            \"count\": len(arr),\n",
        "            \"meaning_min\": float(meaning_min[b]),\n",
        "            \"score_min\": float(score_min[b]),\n",
        "            \"selected\": 0,\n",
        "            \"quota\": 0,\n",
        "            \"meaning_candidates\": int(sum(1 for c in arr if c.get(\"scores\", {}).get(\"meaning\", 0.0) >= meaning_min[b]))\n",
        "        }\n",
        "\n",
        "    # Quota: base 1 per bucket, distribute remainder by bucket size\n",
        "    base_quota = 1\n",
        "    quotas = {b: 0 for b in buckets}\n",
        "    for b in buckets:\n",
        "        quotas[b] = base_quota if buckets[b] else 0\n",
        "\n",
        "    remaining = MAX_FINAL_CLIPS - sum(quotas.values())\n",
        "    if remaining > 0:\n",
        "        order = sorted(buckets.keys(), key=lambda b: len(buckets[b]), reverse=True)\n",
        "        i = 0\n",
        "        while remaining > 0 and order:\n",
        "            quotas[order[i % len(order)]] += 1\n",
        "            remaining -= 1\n",
        "            i += 1\n",
        "\n",
        "    # Late bucket grace: ensure bucket 80-100% has at least 1 if meaning candidates exist\n",
        "    late_bucket = TIME_BUCKETS - 1\n",
        "    if bucket_stats[late_bucket][\"meaning_candidates\"] > 0 and quotas[late_bucket] < 1:\n",
        "        quotas[late_bucket] = 1\n",
        "\n",
        "    for b in quotas:\n",
        "        bucket_stats[b][\"quota\"] = int(quotas[b])\n",
        "\n",
        "    selected = []\n",
        "\n",
        "    def can_add(c):\n",
        "        b = bucket_index(float(c.get(\"start\", 0.0)))\n",
        "        if c.get(\"scores\", {}).get(\"meaning\", 0.0) < meaning_min[b]:\n",
        "            return False, \"below_meaning_min\"\n",
        "        if c.get(\"scores\", {}).get(\"viral_score\", 0.0) < score_min[b]:\n",
        "            return False, \"below_bucket_score_min\"\n",
        "        for s in selected:\n",
        "            if overlaps(c[\"start\"], c[\"end\"], s[\"start\"], s[\"end\"], gap=MIN_GAP_SEC):\n",
        "                return False, f\"overlap_or_gap_with_{s['id']}\"\n",
        "        return True, \"ok\"\n",
        "\n",
        "    # Phase 1: quota per bucket\n",
        "    for b in range(TIME_BUCKETS):\n",
        "        need = quotas[b]\n",
        "        if need <= 0:\n",
        "            continue\n",
        "        pool = list(buckets[b])\n",
        "        while need > 0 and pool:\n",
        "            c = pool.pop(0)\n",
        "            ok, why = can_add(c)\n",
        "            if ok:\n",
        "                selected.append(c)\n",
        "                bucket_stats[b][\"selected\"] += 1\n",
        "                selection_audit.append({\"id\": c[\"id\"], \"decision\": \"selected\", \"phase\": \"quota\", \"bucket\": b, \"start\": c[\"start\"], \"score\": c[\"scores\"][\"viral_score\"], \"reason\": why, \"editorial_reason\": c.get(\"editorial_reason\", [])})\n",
        "                need -= 1\n",
        "            else:\n",
        "                selection_audit.append({\"id\": c[\"id\"], \"decision\": \"rejected\", \"phase\": \"quota\", \"bucket\": b, \"start\": c[\"start\"], \"score\": c[\"scores\"][\"viral_score\"], \"reason\": why, \"editorial_reason\": c.get(\"editorial_reason\", [])})\n",
        "\n",
        "    # Phase 2: global fill\n",
        "    if len(selected) < MAX_FINAL_CLIPS:\n",
        "        remaining = sorted([c for c in CANDIDATES if c not in selected], key=lambda c: (-c.get(\"scores\", {}).get(\"viral_score\", 0.0), c.get(\"start\", 0.0), c.get(\"id\", \"\")))\n",
        "        for c in remaining:\n",
        "            if len(selected) >= MAX_FINAL_CLIPS:\n",
        "                break\n",
        "            ok, why = can_add(c)\n",
        "            b = bucket_index(float(c.get(\"start\", 0.0)))\n",
        "            if not ok:\n",
        "                selection_audit.append({\"id\": c[\"id\"], \"decision\": \"rejected\", \"phase\": \"fill\", \"bucket\": b, \"start\": c[\"start\"], \"score\": c[\"scores\"][\"viral_score\"], \"reason\": why, \"editorial_reason\": c.get(\"editorial_reason\", [])})\n",
        "                continue\n",
        "            selected.append(c)\n",
        "            bucket_stats[b][\"selected\"] += 1\n",
        "            selection_audit.append({\"id\": c[\"id\"], \"decision\": \"selected\", \"phase\": \"fill\", \"bucket\": b, \"start\": c[\"start\"], \"score\": c[\"scores\"][\"viral_score\"], \"reason\": \"ok\", \"editorial_reason\": c.get(\"editorial_reason\", [])})\n",
        "\n",
        "    # Chronological output\n",
        "    SELECTED = sorted(selected, key=lambda c: (c[\"start\"], c[\"id\"]))\n",
        "    write_json(ART_DIR / \"selected.json\", SELECTED)\n",
        "    write_json(ART_DIR / \"selection_audit.json\", selection_audit)\n",
        "    write_json(OUT_DIR / \"selection_audit.json\", selection_audit)\n",
        "    write_json(OUT_DIR / \"bucket_stats.json\", bucket_stats)\n",
        "\n",
        "    logger.info(\"=== SELECTED CLIPS (chronological) ===\")\n",
        "    for j, c in enumerate(SELECTED, 1):\n",
        "        rs = c.get(\"scores\", {})\n",
        "        logger.info(f\"#{j:02d} {c['id']} | VS={rs.get('viral_score',0):.1f} | {c['start']:.2f}-{c['end']:.2f} ({c['duration']:.1f}s)\")\n",
        "    logger.info(f\"Selected clips: {len(SELECTED)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8d44d5-e670-4df0-aa69-9be7508bdaf9",
      "metadata": {},
      "source": [
        "## üß© NON-CORE: Packaging (Caption + Hashtag) ‚Äî setelah Selection (tidak mempengaruhi scoring)\n",
        "\n",
        "- Dijalankan **setelah Stage 10** agar tidak mempengaruhi ranking/selection.\n",
        "- Memanfaatkan hasil ASR `TRANSCRIPTS` jika tersedia.\n",
        "- Jika ASR tidak tersedia/kosong, caption akan fallback deterministik.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d92d6d7-dcb9-4f5b-92e2-9964b66de264",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-30T12:04:50.451318Z",
          "iopub.status.idle": "2026-01-30T12:04:50.451719Z",
          "shell.execute_reply": "2026-01-30T12:04:50.451553Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.451528Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# NON-CORE: Packaging (Caption + Hashtag) ‚Äî LOG ONLY (after selection)\n",
        "# =========================\n",
        "\n",
        "def _dedupe_keep_order(xs):\n",
        "    out = []\n",
        "    for x in xs:\n",
        "        if x and x not in out:\n",
        "            out.append(x)\n",
        "    return out\n",
        "\n",
        "def build_caption_and_hashtags(clip: Dict[str,Any], transcript_text: str):\n",
        "    \"\"\"NON-CORE. Deterministic caption/hashtags berbasis transcript (ASR).\n",
        "    Tidak pernah dipakai untuk scoring/selection.\n",
        "    \"\"\"\n",
        "    s = clip.get(\"scores\", {}) or {}\n",
        "    text_raw = (transcript_text or \"\").strip()\n",
        "    if not text_raw:\n",
        "        return \"Bagian paling seru di obrolan ini üéØ\", [\"#shorts\",\"#reels\",\"#tiktok\",\"#podcast\"]\n",
        "\n",
        "    text_lc = text_raw.lower()\n",
        "\n",
        "    parts = re.split(r'(?<=[\\.!\\?])\\s+|\\n+', text_raw)\n",
        "    if len(parts) == 1:\n",
        "        parts = re.split(r'[;,]\\s+', text_raw)\n",
        "    parts = [p.strip() for p in parts if p.strip()] or [text_raw]\n",
        "\n",
        "    trigger = set((TRIGGER_WORDS if \"TRIGGER_WORDS\" in globals() else []) + [\"haha\",\"wk\"])\n",
        "    laugh  = set([\"wkwk\",\"wkwkwk\",\"ngakak\",\"ketawa\",\"haha\",\"wk\"])\n",
        "\n",
        "    def sent_score(sent: str) -> float:\n",
        "        lc = sent.lower()\n",
        "        toks = re.findall(r\"[a-z0-9']+\", lc)\n",
        "        trig = sum(1 for t in toks if t in trigger)\n",
        "        laug = sum(1 for t in toks if t in laugh)\n",
        "        punct = 2*sent.count(\"!\") + 2*sent.count(\"?\")\n",
        "        twist = 2 if (\"ternyata\" in lc or \"plot twist\" in lc or (\"plot\" in lc and \"twist\" in lc)) else 0\n",
        "        chaos = 1 if any(w in lc for w in [\"anjir\",\"anjay\",\"gila\",\"parah\",\"buset\",\"astaga\",\"waduh\",\"yaampun\"]) else 0\n",
        "\n",
        "        L = len(sent)\n",
        "        len_pen = (-1 if L < 25 else 0) + (-1 if L > 110 else 0)\n",
        "        return trig*3 + laug*3 + punct + twist*2 + chaos + len_pen\n",
        "\n",
        "    best = max(parts, key=sent_score)\n",
        "\n",
        "    # kalau terlalu pendek, gabung neighbor biar ‚Äúberdiri sendiri‚Äù\n",
        "    best_words = re.findall(r\"[a-z0-9']+\", best.lower())\n",
        "    if len(best_words) < 4 and len(parts) > 1:\n",
        "        bi = parts.index(best)\n",
        "        if bi > 0:\n",
        "            best = (parts[bi-1] + \" \" + best).strip()\n",
        "        elif bi < len(parts)-1:\n",
        "            best = (best + \" \" + parts[bi+1]).strip()\n",
        "\n",
        "    snippet = re.sub(r\"\\s+\",\" \", best).strip()\n",
        "    if len(snippet) > 92:\n",
        "        snippet = snippet[:92].rsplit(\" \", 1)[0] + \"‚Ä¶\"\n",
        "\n",
        "    lc = best.lower()\n",
        "    if (\"ternyata\" in lc) or (\"plot twist\" in lc) or (\"plot\" in lc and \"twist\" in lc):\n",
        "        caption = f\"Plot twist: ‚Äú{snippet}‚Äù üëÄ\"\n",
        "    elif any(w in lc for w in [\"ngakak\",\"ketawa\",\"wkwk\",\"wkwkwk\",\"haha\"]):\n",
        "        caption = f\"Ngakak dulu: ‚Äú{snippet}‚Äù üòÇ\"\n",
        "    elif any(w in lc for w in [\"anjir\",\"anjay\",\"gila\",\"parah\",\"buset\",\"astaga\",\"waduh\",\"yaampun\"]):\n",
        "        caption = f\"Chaos dikit: ‚Äú{snippet}‚Äù üî•\"\n",
        "    elif (\"?\" in best) or any(w in lc for w in [\"kok\",\"loh\",\"hah\"]):\n",
        "        caption = f\"Kok bisa? ‚Äú{snippet}‚Äù ü§Ø\"\n",
        "    else:\n",
        "        caption = f\"‚Äú{snippet}‚Äù üéØ\"\n",
        "\n",
        "    base = [\"#shorts\",\"#reels\",\"#tiktok\",\"#podcast\"]\n",
        "    extras = []\n",
        "\n",
        "    topic_rules = [\n",
        "        (r\"\\b(ngakak|ketawa|wkwk|wkwkwk|lucu|komedi|kocak)\\b\", \"#komedi\"),\n",
        "        (r\"\\b(marah|emosi|ribut|debat|berantem|panas)\\b\", \"#debat\"),\n",
        "        (r\"\\b(duit|uang|cuan|bisnis|jualan|modal|untung|rugi|investasi|saham|crypto|forex)\\b\", \"#keuangan\"),\n",
        "        (r\"\\b(politik|pemilu|presiden|menteri|dpr)\\b\", \"#politik\"),\n",
        "        (r\"\\b(cinta|pacar|mantan|nikah)\\b\", \"#relationship\"),\n",
        "        (r\"\\b(game|ml|mobile legends|valorant|pubg|ff|free fire)\\b\", \"#gaming\"),\n",
        "        (r\"\\b(makanan|kuliner|masak|pedas|enak)\\b\", \"#kuliner\"),\n",
        "    ]\n",
        "    for pat, tag in topic_rules:\n",
        "        if re.search(pat, text_lc):\n",
        "            extras.append(tag)\n",
        "\n",
        "    if re.search(r\"\\b(anjir|anjay|gila|parah|buset|astaga|waduh|yaampun)\\b\", text_lc):\n",
        "        extras.append(\"#chaos\")\n",
        "    if re.search(r\"\\b(ternyata|plot|twist)\\b\", text_lc):\n",
        "        extras.append(\"#plottwist\")\n",
        "\n",
        "    if float(s.get(\"viral_score\", 0.0)) >= 80:\n",
        "        extras.append(\"#viral\")\n",
        "\n",
        "    tags = _dedupe_keep_order(base + extras)\n",
        "    return caption, tags[:8]\n",
        "\n",
        "# Attach packaging to SELECTED (log-only). Never read by scoring/selection.\n",
        "missing = 0\n",
        "for c in SELECTED:\n",
        "    if c.get(\"caption\") and c.get(\"hashtags\"):\n",
        "        continue\n",
        "    cid = c.get(\"id\")\n",
        "    t = \"\"\n",
        "    if \"TRANSCRIPTS\" in globals() and isinstance(TRANSCRIPTS, dict):\n",
        "        # In this pipeline, TRANSCRIPTS is keyed by candidate id.\n",
        "        t = (TRANSCRIPTS.get(cid, {}) or {}).get(\"text\", \"\") or \"\"\n",
        "    if not t:\n",
        "        missing += 1\n",
        "    cap, tags = build_caption_and_hashtags(c, t)\n",
        "    c[\"caption\"] = cap\n",
        "    c[\"hashtags\"] = tags\n",
        "\n",
        "logger.info(f\"Packaging attached to SELECTED (log-only). Missing transcript for {missing}/{len(SELECTED)} selected clips.\")\n",
        "log_flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a59344b-e0d0-4818-9619-7edf0a52ca80",
      "metadata": {},
      "source": [
        "## ‚úÖ Log Rapi: Tabel Clip Terpilih (Bahasa Indonesia + Caption/Hashtag)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94299696-2e63-46ac-80dd-5ccac3171921",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-30T12:04:50.453797Z",
          "iopub.status.idle": "2026-01-30T12:04:50.454431Z",
          "shell.execute_reply": "2026-01-30T12:04:50.454276Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.454254Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Clip Terpilih (Rapi, Bahasa Indonesia) ‚Äî termasuk Caption & Hashtag (preview)\n",
        "# =========================\n",
        "import pandas as pd\n",
        "\n",
        "def _safe_join(xs):\n",
        "    if not xs:\n",
        "        return \"\"\n",
        "    return \" \".join([str(x) for x in xs if x])\n",
        "\n",
        "rows = []\n",
        "for rank, c in enumerate(SELECTED, 1):\n",
        "    s = c.get(\"scores\", {}) or {}\n",
        "    rows.append({\n",
        "        \"peringkat\": rank,\n",
        "        \"id_segmen\": c.get(\"id\"),\n",
        "        \"tipe_segmen\": c.get(\"type\"),\n",
        "        \"mulai_detik\": float(c.get(\"start\", 0.0)),\n",
        "        \"akhir_detik\": float(c.get(\"end\", 0.0)),\n",
        "        \"durasi_detik\": float(c.get(\"duration\", 0.0)),\n",
        "        \"skor_viral_total\": float(s.get(\"viral_score\", 0.0)),\n",
        "        \"skor_hook\": float(s.get(\"hook\", 0.0)),\n",
        "        \"skor_emosi\": float(s.get(\"emotion\", 0.0)),\n",
        "        \"skor_kepadatan_info\": float(s.get(\"density\", 0.0)),\n",
        "        \"skor_alur_cerita\": float(s.get(\"arc\", 0.0)),\n",
        "        \"skor_keamanan_audio\": float(s.get(\"safety\", 0.0)),\n",
        "        \"skor_kebaruan\": float(s.get(\"novelty\", 0.0)),\n",
        "        \"caption\": c.get(\"caption\", \"\"),\n",
        "        \"hashtag\": _safe_join(c.get(\"hashtags\", [])) if isinstance(c.get(\"hashtags\"), list) else str(c.get(\"hashtags\") or \"\"),\n",
        "        \"alasan_editorial\": _safe_join(c.get(\"editorial_reason\", [])) if isinstance(c.get(\"editorial_reason\"), list) else str(c.get(\"editorial_reason\") or \"\"),\n",
        "    })\n",
        "\n",
        "df_clip_terpilih = pd.DataFrame(rows)\n",
        "df_clip_terpilih\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05034c47-f5f3-45a9-9d2f-719122934677",
      "metadata": {},
      "source": [
        "## ‚úÇÔ∏è Stage 11: Cut Rules (Snap to Word/Silence + Avoid Shot-Cut)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2bd91a3-bfd3-4a28-9dd8-1b1d9017e6ae",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-30T12:04:50.455741Z",
          "iopub.status.idle": "2026-01-30T12:04:50.456208Z",
          "shell.execute_reply": "2026-01-30T12:04:50.456021Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.456001Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Stage 11: Cut Rules (Snap to Word/Silence + End-of-Idea Polish)\n",
        "# =========================\n",
        "\n",
        "def snap_to_words(start: float, end: float, words: List[Dict[str,Any]], radius: float=1.4):\n",
        "    if not words:\n",
        "        return start, end\n",
        "    ws = [w for w in words if (start - radius) <= w[\"start\"] <= (start + radius)]\n",
        "    if ws:\n",
        "        prior = [w for w in ws if w[\"start\"] <= start]\n",
        "        if prior:\n",
        "            start = max(prior, key=lambda w: w[\"start\"])[\"start\"]\n",
        "        else:\n",
        "            start = min(ws, key=lambda w: abs(w[\"start\"]-start))[\"start\"]\n",
        "\n",
        "    we = [w for w in words if (end - radius) <= w[\"end\"] <= (end + radius)]\n",
        "    if we:\n",
        "        after = [w for w in we if w[\"end\"] >= end]\n",
        "        if after:\n",
        "            end = min(after, key=lambda w: w[\"end\"])[\"end\"]\n",
        "        else:\n",
        "            end = min(we, key=lambda w: abs(w[\"end\"]-end))[\"end\"]\n",
        "    return start, end\n",
        "\n",
        "\n",
        "def snap_to_silence_edges(start: float, end: float, silence_segments: List[List[float]], radius: float=1.0):\n",
        "    best_s = start\n",
        "    cand = [(s,e) for s,e in silence_segments if abs(e-start) <= radius and e <= start]\n",
        "    if cand:\n",
        "        best_s = max(cand, key=lambda x: x[1])[1]\n",
        "\n",
        "    best_e = end\n",
        "    cand2 = [(s,e) for s,e in silence_segments if abs(s-end) <= radius and s >= end]\n",
        "    if cand2:\n",
        "        best_e = min(cand2, key=lambda x: x[0])[0]\n",
        "    return best_s, best_e\n",
        "\n",
        "\n",
        "def avoid_shot_cut(t: float, shot_cuts: List[float], min_dist=0.30, shift=0.35, direction=+1):\n",
        "    if not shot_cuts:\n",
        "        return t\n",
        "    for c in shot_cuts:\n",
        "        if abs(c - t) < min_dist:\n",
        "            return t + direction * shift\n",
        "    return t\n",
        "\n",
        "# --- Editorial helpers ---\n",
        "TAIL_EXT_SEC = 1.2\n",
        "TAIL_MAX_SEC = 2.0\n",
        "LEAD_SILENCE_TRIM_SEC = 0.8\n",
        "START_EXPAND_MIN = 2.0\n",
        "START_EXPAND_MAX = 6.0\n",
        "START_SPEECH_WINDOW = 0.6\n",
        "\n",
        "\n",
        "def _find_silence_start_after(t: float, silence_segments: List[List[float]], max_after: float):\n",
        "    best = None\n",
        "    for s, e in silence_segments:\n",
        "        if s >= t and s <= (t + max_after):\n",
        "            if best is None or s < best:\n",
        "                best = s\n",
        "    return best\n",
        "\n",
        "\n",
        "def _find_silence_end_before(t: float, silence_segments: List[List[float]], min_before: float, max_before: float):\n",
        "    cand = []\n",
        "    for s, e in silence_segments:\n",
        "        if e <= t:\n",
        "            d = t - e\n",
        "            if min_before <= d <= max_before:\n",
        "                cand.append((d, e))\n",
        "    if not cand:\n",
        "        return None\n",
        "    cand.sort(key=lambda x: x[0])\n",
        "    return float(cand[0][1])\n",
        "\n",
        "\n",
        "def _next_word_end_after(t: float, words: List[Dict[str,Any]], max_after: float):\n",
        "    cand = []\n",
        "    for w in words or []:\n",
        "        if \"end\" not in w:\n",
        "            continue\n",
        "        we = float(w[\"end\"])\n",
        "        if we >= t and we <= (t + max_after):\n",
        "            cand.append(we)\n",
        "    return min(cand) if cand else None\n",
        "\n",
        "\n",
        "def _prev_word_start_before(t: float, words: List[Dict[str,Any]], min_before: float, max_before: float):\n",
        "    cand = []\n",
        "    for w in words or []:\n",
        "        if \"start\" not in w:\n",
        "            continue\n",
        "        ws = float(w[\"start\"])\n",
        "        if ws <= t:\n",
        "            d = t - ws\n",
        "            if min_before <= d <= max_before:\n",
        "                cand.append((d, ws))\n",
        "    if not cand:\n",
        "        return None\n",
        "    cand.sort(key=lambda x: x[0])\n",
        "    return float(cand[0][1])\n",
        "\n",
        "\n",
        "def _speech_active_near_end(t: float, words: List[Dict[str,Any]], window: float = 0.6):\n",
        "    if not words:\n",
        "        return False\n",
        "    lo = t - window\n",
        "    hi = t + 0.2\n",
        "    for w in words:\n",
        "        if \"end\" not in w:\n",
        "            continue\n",
        "        we = float(w[\"end\"])\n",
        "        if lo <= we <= hi:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def _speech_active_near_start(t: float, words: List[Dict[str,Any]], window: float = 0.6):\n",
        "    if not words:\n",
        "        return False\n",
        "    lo = t - window\n",
        "    hi = t + 0.2\n",
        "    for w in words:\n",
        "        if \"start\" not in w:\n",
        "            continue\n",
        "        ws = float(w[\"start\"])\n",
        "        if lo <= ws <= hi:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def _add_reason(c: Dict[str,Any], msg: str):\n",
        "    er = c.get(\"editorial_reason\", [])\n",
        "    if not isinstance(er, list):\n",
        "        er = [str(er)]\n",
        "    if msg not in er:\n",
        "        er.append(msg)\n",
        "    c[\"editorial_reason\"] = er\n",
        "\n",
        "\n",
        "with StageTimer(11, \"Snap boundaries + end-of-idea polish\"):\n",
        "    if globals().get(\"_SNAP_DONE\"):\n",
        "        logger.info(\"Stage 11 already completed; skipping duplicate run\")\n",
        "        log_flush()\n",
        "    else:\n",
        "        TRANSCRIPTS = globals().get(\"TRANSCRIPTS\", {})\n",
        "        if not isinstance(TRANSCRIPTS, dict):\n",
        "            TRANSCRIPTS = {}\n",
        "\n",
        "        # Selected-only ASR full if missing or light\n",
        "        ASR_AVAILABLE = bool(globals().get(\"ASR_AVAILABLE\", False)) and (\"transcribe_candidate_abs\" in globals())\n",
        "        if ASR_AVAILABLE:\n",
        "            def transcribe_candidate_abs_local(candidate):\n",
        "                return globals()[\"transcribe_candidate_abs\"](candidate, mode=\"full\")\n",
        "        else:\n",
        "            def transcribe_candidate_abs_local(candidate):\n",
        "                return {\"text\":\"\", \"words\":[], \"markers_abs\":[], \"words_per_sec\":0.0, \"trigger_count\":0, \"word_count\":0}\n",
        "\n",
        "        for c in SELECTED:\n",
        "            cid = c.get(\"id\")\n",
        "            tinfo = TRANSCRIPTS.get(cid, {}) if isinstance(TRANSCRIPTS, dict) else {}\n",
        "            if cid and (cid not in TRANSCRIPTS or tinfo.get(\"mode\") != \"full\"):\n",
        "                try:\n",
        "                    logger.info(f\"ASR (selected-only full) {cid} for snapping\")\n",
        "                    out = transcribe_candidate_abs_local(c)\n",
        "                    TRANSCRIPTS[cid] = out\n",
        "                    if out.get(\"words\"):\n",
        "                        _add_reason(c, \"asr:selected_full\")\n",
        "                    else:\n",
        "                        _add_reason(c, \"asr:selected_full_empty\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Selected-only ASR failed for {cid}: {e}\")\n",
        "                    _add_reason(c, \"asr:selected_full_failed\")\n",
        "\n",
        "        # Apply snapping + editorial polish\n",
        "        for c in SELECTED:\n",
        "            cid = c.get(\"id\")\n",
        "            s = float(c[\"start\"]); e = float(c[\"end\"])\n",
        "\n",
        "            # avoid cutting right on a shot-cut\n",
        "            s_before, e_before = s, e\n",
        "            s = avoid_shot_cut(s, SHOT_CUTS, direction=+1)\n",
        "            if s != s_before:\n",
        "                _add_reason(c, f\"avoid_shot_cut:start(+{s - s_before:.2f}s)\")\n",
        "\n",
        "            e = avoid_shot_cut(e, SHOT_CUTS, direction=+1)\n",
        "            if e != e_before:\n",
        "                _add_reason(c, f\"avoid_shot_cut:end(+{e - e_before:.2f}s)\")\n",
        "\n",
        "            words = (TRANSCRIPTS.get(cid, {}) or {}).get(\"words\", []) or []\n",
        "\n",
        "            # trim leading silence if any\n",
        "            for (ss,se) in SILENCE_SEGMENTS:\n",
        "                if se <= s and (s - se) <= LEAD_SILENCE_TRIM_SEC:\n",
        "                    s = float(se)\n",
        "                    _add_reason(c, \"trim:leading_silence\")\n",
        "                    break\n",
        "\n",
        "            # context expansion (2-6s) if speech is active at start\n",
        "            if _speech_active_near_start(s, words, window=START_SPEECH_WINDOW):\n",
        "                sil_prev = _find_silence_end_before(s, SILENCE_SEGMENTS, START_EXPAND_MIN, START_EXPAND_MAX)\n",
        "                if sil_prev is not None:\n",
        "                    s = float(sil_prev)\n",
        "                    _add_reason(c, f\"context:expand_silence(-{s_before - s:.2f}s)\")\n",
        "                else:\n",
        "                    ws_prev = _prev_word_start_before(s, words, START_EXPAND_MIN, START_EXPAND_MAX)\n",
        "                    if ws_prev is not None:\n",
        "                        s = float(ws_prev)\n",
        "                        _add_reason(c, f\"context:expand_word(-{s_before - s:.2f}s)\")\n",
        "\n",
        "            # snap to word boundaries\n",
        "            s2, e2 = snap_to_words(s, e, words, radius=1.4)\n",
        "            _add_reason(c, \"snap:word\" if words else \"snap:nowords\")\n",
        "\n",
        "            # if snapping made it too short, try silence edges\n",
        "            if (e2 - s2) < MIN_CLIP_SEC:\n",
        "                s2, e2 = snap_to_silence_edges(s, e, SILENCE_SEGMENTS, radius=1.0)\n",
        "                _add_reason(c, \"snap:silence_fallback\")\n",
        "\n",
        "            # clamp to video bounds\n",
        "            s2 = max(0.0, float(s2))\n",
        "            e2 = min(float(ANALYZED_DURATION), float(e2))\n",
        "            if (e2 - s2) < MIN_CLIP_SEC:\n",
        "                logger.warning(f\"Snap too short for {cid}; keeping original bounds\")\n",
        "                _add_reason(c, \"snap:too_short_keep_original\")\n",
        "                continue\n",
        "\n",
        "            # --- End-of-idea polish (even if dur <= max) ---\n",
        "            hard_cap = min(float(ANALYZED_DURATION), float(s2 + MAX_CLIP_SEC))\n",
        "            still_speaking = _speech_active_near_end(e2, words, window=0.6)\n",
        "\n",
        "            if still_speaking and e2 < hard_cap:\n",
        "                sil = _find_silence_start_after(e2, SILENCE_SEGMENTS, max_after=min(TAIL_MAX_SEC, hard_cap - e2))\n",
        "                if sil is not None:\n",
        "                    e2 = min(float(sil), hard_cap)\n",
        "                    _add_reason(c, f\"end:seek_silence(+{e2 - e_before:.2f}s)\")\n",
        "                else:\n",
        "                    wend = _next_word_end_after(e2, words, max_after=min(TAIL_EXT_SEC, hard_cap - e2))\n",
        "                    if wend is not None:\n",
        "                        e2 = min(float(wend), hard_cap)\n",
        "                        _add_reason(c, f\"end:seek_word(+{e2 - e_before:.2f}s)\")\n",
        "                    else:\n",
        "                        e2 = min(float(e2 + min(TAIL_EXT_SEC, hard_cap - e2)), hard_cap)\n",
        "                        _add_reason(c, f\"end:extend(+{e2 - e_before:.2f}s)\")\n",
        "            elif not still_speaking:\n",
        "                # trim meaningless tail if silence starts shortly before end\n",
        "                for (ss,se) in SILENCE_SEGMENTS:\n",
        "                    if ss <= e2 and (e2 - ss) <= 1.2:\n",
        "                        new_e = float(ss)\n",
        "                        if (new_e - s2) >= MIN_CLIP_SEC:\n",
        "                            e2 = new_e\n",
        "                            _add_reason(c, \"end:trim_to_silence\")\n",
        "                        break\n",
        "\n",
        "            # --- Editorial clamp if over max ---\n",
        "            dur = (e2 - s2)\n",
        "            if dur > MAX_CLIP_SEC:\n",
        "                _add_reason(c, f\"clamp:max_sec({MAX_CLIP_SEC:.1f})\")\n",
        "                hard_end = float(s2 + MAX_CLIP_SEC)\n",
        "                e_limit = min(float(e2), float(ANALYZED_DURATION))\n",
        "\n",
        "                still_speaking = _speech_active_near_end(hard_end, words, window=0.6)\n",
        "                if still_speaking:\n",
        "                    _add_reason(c, \"end:still_speaking\")\n",
        "                    sil = _find_silence_start_after(hard_end, SILENCE_SEGMENTS, max_after=TAIL_MAX_SEC)\n",
        "                    if sil is not None:\n",
        "                        e2 = min(float(sil), e_limit)\n",
        "                        _add_reason(c, f\"end:silence(+{e2 - hard_end:.2f}s)\")\n",
        "                    else:\n",
        "                        wend = _next_word_end_after(hard_end, words, max_after=min(TAIL_EXT_SEC, TAIL_MAX_SEC))\n",
        "                        if wend is not None:\n",
        "                            e2 = min(float(wend), e_limit)\n",
        "                            _add_reason(c, f\"end:word(+{e2 - hard_end:.2f}s)\")\n",
        "                        else:\n",
        "                            e2 = min(float(hard_end + min(TAIL_EXT_SEC, TAIL_MAX_SEC)), e_limit)\n",
        "                            _add_reason(c, f\"end:extend(+{e2 - hard_end:.2f}s)\")\n",
        "                else:\n",
        "                    e2 = min(float(hard_end), e_limit)\n",
        "                    _add_reason(c, \"end:hard_end\")\n",
        "\n",
        "            # final safety\n",
        "            e2 = min(float(ANALYZED_DURATION), float(e2))\n",
        "            if e2 <= s2:\n",
        "                logger.warning(f\"Bad bounds after clamp for {cid}; keeping original bounds\")\n",
        "                _add_reason(c, \"bounds:bad_keep_original\")\n",
        "                continue\n",
        "            if (e2 - s2) < MIN_CLIP_SEC:\n",
        "                logger.warning(f\"Too short after clamp for {cid}; keeping original bounds\")\n",
        "                _add_reason(c, \"bounds:too_short_keep_original\")\n",
        "                continue\n",
        "\n",
        "            c[\"start\"] = float(s2)\n",
        "            c[\"end\"] = float(e2)\n",
        "            c[\"duration\"] = float(e2 - s2)\n",
        "\n",
        "        write_json(ART_DIR / \"selected_snapped.json\", SELECTED)\n",
        "        logger.info(\"Snapping completed (end-of-idea polish enabled).\")\n",
        "\n",
        "        try:\n",
        "            write_json(ART_DIR / \"transcript.json\", TRANSCRIPTS)\n",
        "            logger.info(f\"Saved transcript cache after snapping (entries={len(TRANSCRIPTS)})\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to save transcript cache after snapping: {e}\")\n",
        "\n",
        "        globals()[\"TRANSCRIPTS\"] = TRANSCRIPTS\n",
        "        globals()[\"_SNAP_DONE\"] = True\n",
        "        log_flush()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d44c5fa-570d-4d44-9c0b-705cb300b016",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-30T12:04:50.457847Z",
          "iopub.status.idle": "2026-01-30T12:04:50.458270Z",
          "shell.execute_reply": "2026-01-30T12:04:50.458116Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.458071Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Stage 11: Cut Rules (Snap to Word/Silence + End-of-Idea Polish)\n",
        "# =========================\n",
        "\n",
        "def snap_to_words(start: float, end: float, words: List[Dict[str,Any]], radius: float=1.4):\n",
        "    if not words:\n",
        "        return start, end\n",
        "    ws = [w for w in words if (start - radius) <= w[\"start\"] <= (start + radius)]\n",
        "    if ws:\n",
        "        prior = [w for w in ws if w[\"start\"] <= start]\n",
        "        if prior:\n",
        "            start = max(prior, key=lambda w: w[\"start\"])[\"start\"]\n",
        "        else:\n",
        "            start = min(ws, key=lambda w: abs(w[\"start\"]-start))[\"start\"]\n",
        "\n",
        "    we = [w for w in words if (end - radius) <= w[\"end\"] <= (end + radius)]\n",
        "    if we:\n",
        "        after = [w for w in we if w[\"end\"] >= end]\n",
        "        if after:\n",
        "            end = min(after, key=lambda w: w[\"end\"])[\"end\"]\n",
        "        else:\n",
        "            end = min(we, key=lambda w: abs(w[\"end\"]-end))[\"end\"]\n",
        "    return start, end\n",
        "\n",
        "\n",
        "def snap_to_silence_edges(start: float, end: float, silence_segments: List[List[float]], radius: float=1.0):\n",
        "    best_s = start\n",
        "    cand = [(s,e) for s,e in silence_segments if abs(e-start) <= radius and e <= start]\n",
        "    if cand:\n",
        "        best_s = max(cand, key=lambda x: x[1])[1]\n",
        "\n",
        "    best_e = end\n",
        "    cand2 = [(s,e) for s,e in silence_segments if abs(s-end) <= radius and s >= end]\n",
        "    if cand2:\n",
        "        best_e = min(cand2, key=lambda x: x[0])[0]\n",
        "    return best_s, best_e\n",
        "\n",
        "\n",
        "def avoid_shot_cut(t: float, shot_cuts: List[float], min_dist=0.30, shift=0.35, direction=+1):\n",
        "    if not shot_cuts:\n",
        "        return t\n",
        "    for c in shot_cuts:\n",
        "        if abs(c - t) < min_dist:\n",
        "            return t + direction * shift\n",
        "    return t\n",
        "\n",
        "# --- Editorial helpers ---\n",
        "TAIL_EXT_SEC = 1.2\n",
        "TAIL_MAX_SEC = 2.0\n",
        "LEAD_SILENCE_TRIM_SEC = 0.8\n",
        "START_EXPAND_MIN = 2.0\n",
        "START_EXPAND_MAX = 6.0\n",
        "START_SPEECH_WINDOW = 0.6\n",
        "\n",
        "\n",
        "def _find_silence_start_after(t: float, silence_segments: List[List[float]], max_after: float):\n",
        "    best = None\n",
        "    for s, e in silence_segments:\n",
        "        if s >= t and s <= (t + max_after):\n",
        "            if best is None or s < best:\n",
        "                best = s\n",
        "    return best\n",
        "\n",
        "\n",
        "def _find_silence_end_before(t: float, silence_segments: List[List[float]], min_before: float, max_before: float):\n",
        "    cand = []\n",
        "    for s, e in silence_segments:\n",
        "        if e <= t:\n",
        "            d = t - e\n",
        "            if min_before <= d <= max_before:\n",
        "                cand.append((d, e))\n",
        "    if not cand:\n",
        "        return None\n",
        "    cand.sort(key=lambda x: x[0])\n",
        "    return float(cand[0][1])\n",
        "\n",
        "\n",
        "def _next_word_end_after(t: float, words: List[Dict[str,Any]], max_after: float):\n",
        "    cand = []\n",
        "    for w in words or []:\n",
        "        if \"end\" not in w:\n",
        "            continue\n",
        "        we = float(w[\"end\"])\n",
        "        if we >= t and we <= (t + max_after):\n",
        "            cand.append(we)\n",
        "    return min(cand) if cand else None\n",
        "\n",
        "\n",
        "def _prev_word_start_before(t: float, words: List[Dict[str,Any]], min_before: float, max_before: float):\n",
        "    cand = []\n",
        "    for w in words or []:\n",
        "        if \"start\" not in w:\n",
        "            continue\n",
        "        ws = float(w[\"start\"])\n",
        "        if ws <= t:\n",
        "            d = t - ws\n",
        "            if min_before <= d <= max_before:\n",
        "                cand.append((d, ws))\n",
        "    if not cand:\n",
        "        return None\n",
        "    cand.sort(key=lambda x: x[0])\n",
        "    return float(cand[0][1])\n",
        "\n",
        "\n",
        "def _speech_active_near_end(t: float, words: List[Dict[str,Any]], window: float = 0.6):\n",
        "    if not words:\n",
        "        return False\n",
        "    lo = t - window\n",
        "    hi = t + 0.2\n",
        "    for w in words:\n",
        "        if \"end\" not in w:\n",
        "            continue\n",
        "        we = float(w[\"end\"])\n",
        "        if lo <= we <= hi:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def _speech_active_near_start(t: float, words: List[Dict[str,Any]], window: float = 0.6):\n",
        "    if not words:\n",
        "        return False\n",
        "    lo = t - window\n",
        "    hi = t + 0.2\n",
        "    for w in words:\n",
        "        if \"start\" not in w:\n",
        "            continue\n",
        "        ws = float(w[\"start\"])\n",
        "        if lo <= ws <= hi:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def _add_reason(c: Dict[str,Any], msg: str):\n",
        "    er = c.get(\"editorial_reason\", [])\n",
        "    if not isinstance(er, list):\n",
        "        er = [str(er)]\n",
        "    if msg not in er:\n",
        "        er.append(msg)\n",
        "    c[\"editorial_reason\"] = er\n",
        "\n",
        "\n",
        "with StageTimer(11, \"Snap boundaries + end-of-idea polish\"):\n",
        "    if globals().get(\"_SNAP_DONE\"):\n",
        "        logger.info(\"Stage 11 already completed; skipping duplicate run\")\n",
        "        log_flush()\n",
        "    else:\n",
        "        TRANSCRIPTS = globals().get(\"TRANSCRIPTS\", {})\n",
        "        if not isinstance(TRANSCRIPTS, dict):\n",
        "            TRANSCRIPTS = {}\n",
        "\n",
        "        # Selected-only ASR full if missing or light\n",
        "        ASR_AVAILABLE = bool(globals().get(\"ASR_AVAILABLE\", False)) and (\"transcribe_candidate_abs\" in globals())\n",
        "        if ASR_AVAILABLE:\n",
        "            def transcribe_candidate_abs_local(candidate):\n",
        "                return globals()[\"transcribe_candidate_abs\"](candidate, mode=\"full\")\n",
        "        else:\n",
        "            def transcribe_candidate_abs_local(candidate):\n",
        "                return {\"text\":\"\", \"words\":[], \"markers_abs\":[], \"words_per_sec\":0.0, \"trigger_count\":0, \"word_count\":0}\n",
        "\n",
        "        for c in SELECTED:\n",
        "            cid = c.get(\"id\")\n",
        "            tinfo = TRANSCRIPTS.get(cid, {}) if isinstance(TRANSCRIPTS, dict) else {}\n",
        "            if cid and (cid not in TRANSCRIPTS or tinfo.get(\"mode\") != \"full\"):\n",
        "                try:\n",
        "                    logger.info(f\"ASR (selected-only full) {cid} for snapping\")\n",
        "                    out = transcribe_candidate_abs_local(c)\n",
        "                    TRANSCRIPTS[cid] = out\n",
        "                    if out.get(\"words\"):\n",
        "                        _add_reason(c, \"asr:selected_full\")\n",
        "                    else:\n",
        "                        _add_reason(c, \"asr:selected_full_empty\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Selected-only ASR failed for {cid}: {e}\")\n",
        "                    _add_reason(c, \"asr:selected_full_failed\")\n",
        "\n",
        "        # Apply snapping + editorial polish\n",
        "        for c in SELECTED:\n",
        "            cid = c.get(\"id\")\n",
        "            s = float(c[\"start\"]); e = float(c[\"end\"])\n",
        "\n",
        "            # avoid cutting right on a shot-cut\n",
        "            s_before, e_before = s, e\n",
        "            s = avoid_shot_cut(s, SHOT_CUTS, direction=+1)\n",
        "            if s != s_before:\n",
        "                _add_reason(c, f\"avoid_shot_cut:start(+{s - s_before:.2f}s)\")\n",
        "\n",
        "            e = avoid_shot_cut(e, SHOT_CUTS, direction=+1)\n",
        "            if e != e_before:\n",
        "                _add_reason(c, f\"avoid_shot_cut:end(+{e - e_before:.2f}s)\")\n",
        "\n",
        "            words = (TRANSCRIPTS.get(cid, {}) or {}).get(\"words\", []) or []\n",
        "\n",
        "            # trim leading silence if any\n",
        "            for (ss,se) in SILENCE_SEGMENTS:\n",
        "                if se <= s and (s - se) <= LEAD_SILENCE_TRIM_SEC:\n",
        "                    s = float(se)\n",
        "                    _add_reason(c, \"trim:leading_silence\")\n",
        "                    break\n",
        "\n",
        "            # context expansion (2-6s) if speech is active at start\n",
        "            if _speech_active_near_start(s, words, window=START_SPEECH_WINDOW):\n",
        "                sil_prev = _find_silence_end_before(s, SILENCE_SEGMENTS, START_EXPAND_MIN, START_EXPAND_MAX)\n",
        "                if sil_prev is not None:\n",
        "                    s = float(sil_prev)\n",
        "                    _add_reason(c, f\"context:expand_silence(-{s_before - s:.2f}s)\")\n",
        "                else:\n",
        "                    ws_prev = _prev_word_start_before(s, words, START_EXPAND_MIN, START_EXPAND_MAX)\n",
        "                    if ws_prev is not None:\n",
        "                        s = float(ws_prev)\n",
        "                        _add_reason(c, f\"context:expand_word(-{s_before - s:.2f}s)\")\n",
        "\n",
        "            # snap to word boundaries\n",
        "            s2, e2 = snap_to_words(s, e, words, radius=1.4)\n",
        "            _add_reason(c, \"snap:word\" if words else \"snap:nowords\")\n",
        "\n",
        "            # if snapping made it too short, try silence edges\n",
        "            if (e2 - s2) < MIN_CLIP_SEC:\n",
        "                s2, e2 = snap_to_silence_edges(s, e, SILENCE_SEGMENTS, radius=1.0)\n",
        "                _add_reason(c, \"snap:silence_fallback\")\n",
        "\n",
        "            # clamp to video bounds\n",
        "            s2 = max(0.0, float(s2))\n",
        "            e2 = min(float(ANALYZED_DURATION), float(e2))\n",
        "            if (e2 - s2) < MIN_CLIP_SEC:\n",
        "                logger.warning(f\"Snap too short for {cid}; keeping original bounds\")\n",
        "                _add_reason(c, \"snap:too_short_keep_original\")\n",
        "                continue\n",
        "\n",
        "            # --- End-of-idea polish (even if dur <= max) ---\n",
        "            hard_cap = min(float(ANALYZED_DURATION), float(s2 + MAX_CLIP_SEC))\n",
        "            still_speaking = _speech_active_near_end(e2, words, window=0.6)\n",
        "\n",
        "            if still_speaking and e2 < hard_cap:\n",
        "                sil = _find_silence_start_after(e2, SILENCE_SEGMENTS, max_after=min(TAIL_MAX_SEC, hard_cap - e2))\n",
        "                if sil is not None:\n",
        "                    e2 = min(float(sil), hard_cap)\n",
        "                    _add_reason(c, f\"end:seek_silence(+{e2 - e_before:.2f}s)\")\n",
        "                else:\n",
        "                    wend = _next_word_end_after(e2, words, max_after=min(TAIL_EXT_SEC, hard_cap - e2))\n",
        "                    if wend is not None:\n",
        "                        e2 = min(float(wend), hard_cap)\n",
        "                        _add_reason(c, f\"end:seek_word(+{e2 - e_before:.2f}s)\")\n",
        "                    else:\n",
        "                        e2 = min(float(e2 + min(TAIL_EXT_SEC, hard_cap - e2)), hard_cap)\n",
        "                        _add_reason(c, f\"end:extend(+{e2 - e_before:.2f}s)\")\n",
        "            elif not still_speaking:\n",
        "                # trim meaningless tail if silence starts shortly before end\n",
        "                for (ss,se) in SILENCE_SEGMENTS:\n",
        "                    if ss <= e2 and (e2 - ss) <= 1.2:\n",
        "                        new_e = float(ss)\n",
        "                        if (new_e - s2) >= MIN_CLIP_SEC:\n",
        "                            e2 = new_e\n",
        "                            _add_reason(c, \"end:trim_to_silence\")\n",
        "                        break\n",
        "\n",
        "            # --- Editorial clamp if over max ---\n",
        "            dur = (e2 - s2)\n",
        "            if dur > MAX_CLIP_SEC:\n",
        "                _add_reason(c, f\"clamp:max_sec({MAX_CLIP_SEC:.1f})\")\n",
        "                hard_end = float(s2 + MAX_CLIP_SEC)\n",
        "                e_limit = min(float(e2), float(ANALYZED_DURATION))\n",
        "\n",
        "                still_speaking = _speech_active_near_end(hard_end, words, window=0.6)\n",
        "                if still_speaking:\n",
        "                    _add_reason(c, \"end:still_speaking\")\n",
        "                    sil = _find_silence_start_after(hard_end, SILENCE_SEGMENTS, max_after=TAIL_MAX_SEC)\n",
        "                    if sil is not None:\n",
        "                        e2 = min(float(sil), e_limit)\n",
        "                        _add_reason(c, f\"end:silence(+{e2 - hard_end:.2f}s)\")\n",
        "                    else:\n",
        "                        wend = _next_word_end_after(hard_end, words, max_after=min(TAIL_EXT_SEC, TAIL_MAX_SEC))\n",
        "                        if wend is not None:\n",
        "                            e2 = min(float(wend), e_limit)\n",
        "                            _add_reason(c, f\"end:word(+{e2 - hard_end:.2f}s)\")\n",
        "                        else:\n",
        "                            e2 = min(float(hard_end + min(TAIL_EXT_SEC, TAIL_MAX_SEC)), e_limit)\n",
        "                            _add_reason(c, f\"end:extend(+{e2 - hard_end:.2f}s)\")\n",
        "                else:\n",
        "                    e2 = min(float(hard_end), e_limit)\n",
        "                    _add_reason(c, \"end:hard_end\")\n",
        "\n",
        "            # final safety\n",
        "            e2 = min(float(ANALYZED_DURATION), float(e2))\n",
        "            if e2 <= s2:\n",
        "                logger.warning(f\"Bad bounds after clamp for {cid}; keeping original bounds\")\n",
        "                _add_reason(c, \"bounds:bad_keep_original\")\n",
        "                continue\n",
        "            if (e2 - s2) < MIN_CLIP_SEC:\n",
        "                logger.warning(f\"Too short after clamp for {cid}; keeping original bounds\")\n",
        "                _add_reason(c, \"bounds:too_short_keep_original\")\n",
        "                continue\n",
        "\n",
        "            c[\"start\"] = float(s2)\n",
        "            c[\"end\"] = float(e2)\n",
        "            c[\"duration\"] = float(e2 - s2)\n",
        "\n",
        "        write_json(ART_DIR / \"selected_snapped.json\", SELECTED)\n",
        "        logger.info(\"Snapping completed (end-of-idea polish enabled).\")\n",
        "\n",
        "        try:\n",
        "            write_json(ART_DIR / \"transcript.json\", TRANSCRIPTS)\n",
        "            logger.info(f\"Saved transcript cache after snapping (entries={len(TRANSCRIPTS)})\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to save transcript cache after snapping: {e}\")\n",
        "\n",
        "        globals()[\"TRANSCRIPTS\"] = TRANSCRIPTS\n",
        "        globals()[\"_SNAP_DONE\"] = True\n",
        "        log_flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26405bc6-b32a-448d-a121-65317a52c08f",
      "metadata": {},
      "source": [
        "## üì¶ Stage 12: Export (9:16 FIT + Letterbox)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73919423-02dd-4199-b71d-753e462882ad",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-30T12:04:50.459746Z",
          "iopub.status.idle": "2026-01-30T12:04:50.460126Z",
          "shell.execute_reply": "2026-01-30T12:04:50.459961Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.459943Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Stage 12 (ONE CELL): Finalize + Export (NO ZOOM / PAD) + Thumbs + Ranking\n",
        "# =========================\n",
        "\n",
        "import csv\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "EXPORT_W = int(globals().get(\"EXPORT_W\", 1080))\n",
        "EXPORT_H = int(globals().get(\"EXPORT_H\", 1920))\n",
        "FPS_EXPORT = int(globals().get(\"FPS_EXPORT\", 30))  # opsional\n",
        "\n",
        "def run_cmd(cmd: List[str], check: bool = True) -> subprocess.CompletedProcess:\n",
        "    return subprocess.run(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        check=check,\n",
        "    )\n",
        "\n",
        "def _portrait_vf_nozoom() -> str:\n",
        "    \"\"\"\n",
        "    NO ZOOM: scale to fit (decrease) + pad to exact portrait size.\n",
        "    Ini aman untuk acceptance test resolusi, tapi ada black bars.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        f\"scale={EXPORT_W}:{EXPORT_H}:force_original_aspect_ratio=decrease,\"\n",
        "        f\"pad={EXPORT_W}:{EXPORT_H}:(ow-iw)/2:(oh-ih)/2,\"\n",
        "        f\"setsar=1\"\n",
        "    )\n",
        "\n",
        "def export_clip(video_path: Path, out_path: Path, start: float, end: float) -> None:\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-ss\", f\"{start:.3f}\", \"-to\", f\"{end:.3f}\",\n",
        "        \"-i\", str(video_path),\n",
        "        \"-vf\", _portrait_vf_nozoom(),\n",
        "        \"-r\", str(FPS_EXPORT),\n",
        "        \"-c:v\", \"libx264\", \"-preset\", \"veryfast\", \"-crf\", \"20\",\n",
        "        \"-pix_fmt\", \"yuv420p\",\n",
        "        \"-c:a\", \"aac\", \"-b:a\", AUDIO_BITRATE,\n",
        "        \"-movflags\", \"+faststart\",\n",
        "        str(out_path),\n",
        "    ]\n",
        "    run_cmd(cmd, check=True)\n",
        "\n",
        "def _ffprobe_duration(path: Path) -> float:\n",
        "    try:\n",
        "        out = subprocess.check_output([\n",
        "            FFPROBE_BIN, '-v', 'error',\n",
        "            '-show_entries', 'format=duration',\n",
        "            '-of', 'default=noprint_wrappers=1:nokey=1',\n",
        "            str(path)\n",
        "        ]).decode('utf-8').strip()\n",
        "        return float(out)\n",
        "    except Exception:\n",
        "        return -1.0\n",
        "\n",
        "def _validate_clip_file(path: Path, expected_dur: float, tol: float=1.2) -> None:\n",
        "    assert path.exists(), f\"Missing clip file: {path}\"\n",
        "    size = path.stat().st_size\n",
        "    assert size > 50_000, f\"Clip too small / likely failed: {path} ({size} bytes)\"\n",
        "    dur = _ffprobe_duration(path)\n",
        "    assert dur > 0, f\"ffprobe duration failed: {path}\"\n",
        "    # tolerate keyframe/encoder variance\n",
        "    assert abs(dur - expected_dur) <= tol, f\"Bad duration {dur:.2f}s (expected ~{expected_dur:.2f}s) for {path}\"\n",
        "\n",
        "def export_thumb(video_path: Path, out_path: Path, t: float) -> None:\n",
        "\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-ss\", f\"{t:.3f}\",\n",
        "        \"-i\", str(video_path),\n",
        "        \"-vf\", _portrait_vf_nozoom(),\n",
        "        \"-vframes\", \"1\",\n",
        "        \"-q:v\", \"2\",\n",
        "        str(out_path),\n",
        "    ]\n",
        "    run_cmd(cmd, check=True)\n",
        "\n",
        "with StageTimer(12, f\"Finalize + Export (NO ZOOM pad {EXPORT_W}x{EXPORT_H}@{FPS_EXPORT}) + Thumbs + Ranking\"):\n",
        "    assert \"VIDEO_PATH\" in globals(), \"VIDEO_PATH missing\"\n",
        "    assert \"SELECTED\" in globals() and isinstance(SELECTED, list), \"SELECTED missing\"\n",
        "    assert \"CLIPS_DIR\" in globals() and \"THUMBS_DIR\" in globals(), \"CLIPS_DIR/THUMBS_DIR missing\"\n",
        "    assert \"OUT_DIR\" in globals(), \"OUT_DIR missing\"\n",
        "\n",
        "    CLIPS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    THUMBS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # clean old exports\n",
        "    for p in CLIPS_DIR.glob(\"*.mp4\"):\n",
        "        p.unlink()\n",
        "    for p in THUMBS_DIR.glob(\"*.jpg\"):\n",
        "        p.unlink()\n",
        "\n",
        "    ranking_rows = []\n",
        "    for rank, c in enumerate(SELECTED, 1):\n",
        "        cid = str(c.get(\"id\"))\n",
        "        st  = float(c.get(\"start\", 0.0))\n",
        "        en  = float(c.get(\"end\", st))\n",
        "        dur = float(c.get(\"duration\", en - st))\n",
        "        vs  = float((c.get(\"scores\", {}) or {}).get(\"viral_score\", 0.0))\n",
        "\n",
        "        clip_out  = CLIPS_DIR  / f\"clip_{rank:02d}_{cid}.mp4\"\n",
        "        thumb_out = THUMBS_DIR / f\"thumb_{rank:02d}_{cid}.jpg\"\n",
        "\n",
        "        export_clip(VIDEO_PATH, clip_out, st, en)\n",
        "        _validate_clip_file(clip_out, expected_dur=(en-st))\n",
        "\n",
        "        # Mirror to public outputs for Kaggle UI convenience\n",
        "        try:\n",
        "            PUBLIC_CLIPS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "            public_clip = PUBLIC_CLIPS_DIR / clip_out.name\n",
        "            if public_clip.exists():\n",
        "                public_clip.unlink()\n",
        "            public_clip.write_bytes(clip_out.read_bytes())\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Public clip mirror failed: {e}\")\n",
        "\n",
        "        t_thumb = st + min(0.5, max(0.0, dur * 0.10))\n",
        "        export_thumb(VIDEO_PATH, thumb_out, t_thumb)\n",
        "        try:\n",
        "            PUBLIC_THUMBS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "            public_thumb = PUBLIC_THUMBS_DIR / thumb_out.name\n",
        "            if public_thumb.exists():\n",
        "                public_thumb.unlink()\n",
        "            public_thumb.write_bytes(thumb_out.read_bytes())\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Public thumb mirror failed: {e}\")\n",
        "\n",
        "        er = c.get(\"editorial_reason\", [])\n",
        "        er = \" | \".join(er) if isinstance(er, list) else str(er)\n",
        "\n",
        "        ranking_rows.append({\n",
        "            \"rank\": int(rank),\n",
        "            \"id\": cid,\n",
        "            \"start\": float(st),\n",
        "            \"end\": float(en),\n",
        "            \"duration\": float(dur),\n",
        "            \"viral_score\": float(vs),\n",
        "            \"clip_path\": str(clip_out),\n",
        "            \"thumbnail_path\": str(thumb_out),\n",
        "            \"editorial_reason\": er,\n",
        "        })\n",
        "\n",
        "    ranking_csv = OUT_DIR / \"selected_ranking.csv\"\n",
        "    with open(ranking_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        fieldnames = [\"rank\",\"id\",\"start\",\"end\",\"duration\",\"viral_score\",\"clip_path\",\"thumbnail_path\",\"editorial_reason\"]\n",
        "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        w.writeheader()\n",
        "        w.writerows(ranking_rows)\n",
        "\n",
        "    logger.info(f\"‚úÖ Stage 12 done. Ranking: {ranking_csv}\")\n",
        "    log_flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbbbeadd-80e6-4499-b181-31efb1a8d2e2",
      "metadata": {},
      "source": [
        "## üßæ Stage 13: Manifest (JSON/CSV) + Caption/Hashtag (Log Only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8152e63-c360-493b-adbe-7e790b7c6d64",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-30T12:04:50.461706Z",
          "iopub.status.idle": "2026-01-30T12:04:50.462383Z",
          "shell.execute_reply": "2026-01-30T12:04:50.462247Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.462227Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Cell: Stage 13 - Caption/Hashtag helpers (LOG ONLY, Non-Core)\n",
        "# =========================\n",
        "\n",
        "def _dedupe_keep_order(xs):\n",
        "    out = []\n",
        "    for x in xs:\n",
        "        if x and x not in out:\n",
        "            out.append(x)\n",
        "    return out\n",
        "\n",
        "def build_caption_and_hashtags(clip: Dict[str,Any], transcript_text: str):\n",
        "    \"\"\"NON-CORE. Deterministic caption/hashtags berbasis transcript (ASR).\"\"\"\n",
        "    s = clip.get(\"scores\", {}) or {}\n",
        "    text_raw = (transcript_text or \"\").strip()\n",
        "    if not text_raw:\n",
        "        return \"Bagian paling seru di obrolan ini üéØ\", [\"#shorts\",\"#reels\",\"#tiktok\",\"#podcast\"]\n",
        "\n",
        "    text_lc = text_raw.lower()\n",
        "\n",
        "    parts = re.split(r'(?<=[\\.!\\?])\\s+|\\n+', text_raw)\n",
        "    if len(parts) == 1:\n",
        "        parts = re.split(r'[;,]\\s+', text_raw)\n",
        "    parts = [p.strip() for p in parts if p.strip()]\n",
        "    if not parts:\n",
        "        parts = [text_raw]\n",
        "\n",
        "    trigger = set((TRIGGER_WORDS if \"TRIGGER_WORDS\" in globals() else []) + [\"haha\",\"wk\"])\n",
        "    laugh  = set([\"wkwk\",\"wkwkwk\",\"ngakak\",\"ketawa\",\"haha\",\"wk\"])\n",
        "\n",
        "    def sent_score(sent: str) -> float:\n",
        "        lc = sent.lower()\n",
        "        toks = re.findall(r\"[a-z0-9']+\", lc)\n",
        "        trig = sum(1 for t in toks if t in trigger)\n",
        "        laug = sum(1 for t in toks if t in laugh)\n",
        "        punct = 2*sent.count(\"!\") + 2*sent.count(\"?\")\n",
        "        twist = 2 if (\"ternyata\" in lc or \"plot twist\" in lc or (\"plot\" in lc and \"twist\" in lc)) else 0\n",
        "        chaos = 1 if any(w in lc for w in [\"anjir\",\"anjay\",\"gila\",\"parah\",\"buset\",\"astaga\",\"waduh\",\"yaampun\"]) else 0\n",
        "\n",
        "        L = len(sent)\n",
        "        len_pen = 0\n",
        "        if L < 25:  len_pen -= 1\n",
        "        if L > 110: len_pen -= 1\n",
        "        return trig*3 + laug*3 + punct + twist*2 + chaos + len_pen\n",
        "\n",
        "    best_i = max(range(len(parts)), key=lambda i: sent_score(parts[i]))\n",
        "    best = parts[best_i]\n",
        "\n",
        "    best_words = re.findall(r\"[a-z0-9']+\", best.lower())\n",
        "    if len(best_words) < 4 and len(parts) > 1:\n",
        "        if best_i > 0:\n",
        "            best = (parts[best_i-1] + \" \" + best).strip()\n",
        "        elif best_i < len(parts)-1:\n",
        "            best = (best + \" \" + parts[best_i+1]).strip()\n",
        "\n",
        "    snippet = re.sub(r\"\\s+\",\" \", best).strip()\n",
        "    if len(snippet) > 92:\n",
        "        snippet = snippet[:92].rsplit(\" \", 1)[0] + \"‚Ä¶\"\n",
        "\n",
        "    lc = best.lower()\n",
        "    if (\"ternyata\" in lc) or (\"plot twist\" in lc) or (\"plot\" in lc and \"twist\" in lc):\n",
        "        caption = f\"Plot twist: ‚Äú{snippet}‚Äù üëÄ\"\n",
        "    elif any(w in lc for w in [\"ngakak\",\"ketawa\",\"wkwk\",\"wkwkwk\",\"haha\"]):\n",
        "        caption = f\"Ngakak dulu: ‚Äú{snippet}‚Äù üòÇ\"\n",
        "    elif any(w in lc for w in [\"anjir\",\"anjay\",\"gila\",\"parah\",\"buset\",\"astaga\",\"waduh\",\"yaampun\"]):\n",
        "        caption = f\"Chaos dikit: ‚Äú{snippet}‚Äù üî•\"\n",
        "    elif (\"?\" in best) or any(w in lc for w in [\"kok\",\"loh\",\"hah\"]):\n",
        "        caption = f\"Kok bisa? ‚Äú{snippet}‚Äù ü§Ø\"\n",
        "    else:\n",
        "        caption = f\"‚Äú{snippet}‚Äù üéØ\"\n",
        "\n",
        "    base = [\"#shorts\", \"#reels\", \"#tiktok\", \"#podcast\"]\n",
        "    topic_rules = [\n",
        "        (r\"\\b(ngakak|ketawa|wkwk|wkwkwk|lucu|komedi|kocak)\\b\", \"#komedi\"),\n",
        "        (r\"\\b(marah|emosi|ribut|debat|berantem|panas)\\b\", \"#debat\"),\n",
        "        (r\"\\b(duit|uang|cuan|bisnis|jualan|modal|untung|rugi|investasi|saham|crypto|forex)\\b\", \"#keuangan\"),\n",
        "        (r\"\\b(politik|pemilu|presiden|menteri|dpr)\\b\", \"#politik\"),\n",
        "        (r\"\\b(cinta|pacar|mantan|nikah)\\b\", \"#relationship\"),\n",
        "        (r\"\\b(game|ml|mobile legends|valorant|pubg|ff|free fire)\\b\", \"#gaming\"),\n",
        "        (r\"\\b(makanan|kuliner|masak|pedas|enak)\\b\", \"#kuliner\"),\n",
        "    ]\n",
        "    extras = []\n",
        "    for pat, tag in topic_rules:\n",
        "        if re.search(pat, text_lc):\n",
        "            extras.append(tag)\n",
        "\n",
        "    if re.search(r\"\\b(anjir|anjay|gila|parah|buset|astaga|waduh|yaampun)\\b\", text_lc):\n",
        "        extras.append(\"#chaos\")\n",
        "    if re.search(r\"\\b(ternyata|plot|twist)\\b\", text_lc):\n",
        "        extras.append(\"#plottwist\")\n",
        "\n",
        "    vs = float(s.get(\"viral_score\", 0.0))\n",
        "    if vs >= 80:\n",
        "        extras.append(\"#viral\")\n",
        "\n",
        "    tags = _dedupe_keep_order(base + extras)\n",
        "    return caption, tags[:8]\n",
        "\n",
        "# =========================\n",
        "# Cell: Stage 13 - Caption/Hashtag helpers (LOG ONLY, Non-Core)\n",
        "# =========================\n",
        "\n",
        "def _dedupe_keep_order(xs):\n",
        "    out = []\n",
        "    for x in xs:\n",
        "        if x and x not in out:\n",
        "            out.append(x)\n",
        "    return out\n",
        "\n",
        "def build_caption_and_hashtags(clip: Dict[str,Any], transcript_text: str):\n",
        "    \"\"\"NON-CORE. Deterministic caption/hashtags berbasis transcript (ASR).\"\"\"\n",
        "    s = clip.get(\"scores\", {}) or {}\n",
        "    text_raw = (transcript_text or \"\").strip()\n",
        "    if not text_raw:\n",
        "        return \"Bagian paling seru di obrolan ini üéØ\", [\"#shorts\",\"#reels\",\"#tiktok\",\"#podcast\"]\n",
        "\n",
        "    text_lc = text_raw.lower()\n",
        "\n",
        "    parts = re.split(r'(?<=[\\.!\\?])\\s+|\\n+', text_raw)\n",
        "    if len(parts) == 1:\n",
        "        parts = re.split(r'[;,]\\s+', text_raw)\n",
        "    parts = [p.strip() for p in parts if p.strip()]\n",
        "    if not parts:\n",
        "        parts = [text_raw]\n",
        "\n",
        "    trigger = set((TRIGGER_WORDS if \"TRIGGER_WORDS\" in globals() else []) + [\"haha\",\"wk\"])\n",
        "    laugh  = set([\"wkwk\",\"wkwkwk\",\"ngakak\",\"ketawa\",\"haha\",\"wk\"])\n",
        "\n",
        "    def sent_score(sent: str) -> float:\n",
        "        lc = sent.lower()\n",
        "        toks = re.findall(r\"[a-z0-9']+\", lc)\n",
        "        trig = sum(1 for t in toks if t in trigger)\n",
        "        laug = sum(1 for t in toks if t in laugh)\n",
        "        punct = 2*sent.count(\"!\") + 2*sent.count(\"?\")\n",
        "        twist = 2 if (\"ternyata\" in lc or \"plot twist\" in lc or (\"plot\" in lc and \"twist\" in lc)) else 0\n",
        "        chaos = 1 if any(w in lc for w in [\"anjir\",\"anjay\",\"gila\",\"parah\",\"buset\",\"astaga\",\"waduh\",\"yaampun\"]) else 0\n",
        "\n",
        "        L = len(sent)\n",
        "        len_pen = 0\n",
        "        if L < 25:  len_pen -= 1\n",
        "        if L > 110: len_pen -= 1\n",
        "        return trig*3 + laug*3 + punct + twist*2 + chaos + len_pen\n",
        "\n",
        "    best_i = max(range(len(parts)), key=lambda i: sent_score(parts[i]))\n",
        "    best = parts[best_i]\n",
        "\n",
        "    best_words = re.findall(r\"[a-z0-9']+\", best.lower())\n",
        "    if len(best_words) < 4 and len(parts) > 1:\n",
        "        if best_i > 0:\n",
        "            best = (parts[best_i-1] + \" \" + best).strip()\n",
        "        elif best_i < len(parts)-1:\n",
        "            best = (best + \" \" + parts[best_i+1]).strip()\n",
        "\n",
        "    snippet = re.sub(r\"\\s+\",\" \", best).strip()\n",
        "    if len(snippet) > 92:\n",
        "        snippet = snippet[:92].rsplit(\" \", 1)[0] + \"‚Ä¶\"\n",
        "\n",
        "    lc = best.lower()\n",
        "    if (\"ternyata\" in lc) or (\"plot twist\" in lc) or (\"plot\" in lc and \"twist\" in lc):\n",
        "        caption = f\"Plot twist: ‚Äú{snippet}‚Äù üëÄ\"\n",
        "    elif any(w in lc for w in [\"ngakak\",\"ketawa\",\"wkwk\",\"wkwkwk\",\"haha\"]):\n",
        "        caption = f\"Ngakak dulu: ‚Äú{snippet}‚Äù üòÇ\"\n",
        "    elif any(w in lc for w in [\"anjir\",\"anjay\",\"gila\",\"parah\",\"buset\",\"astaga\",\"waduh\",\"yaampun\"]):\n",
        "        caption = f\"Chaos dikit: ‚Äú{snippet}‚Äù üî•\"\n",
        "    elif (\"?\" in best) or any(w in lc for w in [\"kok\",\"loh\",\"hah\"]):\n",
        "        caption = f\"Kok bisa? ‚Äú{snippet}‚Äù ü§Ø\"\n",
        "    else:\n",
        "        caption = f\"‚Äú{snippet}‚Äù üéØ\"\n",
        "\n",
        "    base = [\"#shorts\", \"#reels\", \"#tiktok\", \"#podcast\"]\n",
        "    topic_rules = [\n",
        "        (r\"\\b(ngakak|ketawa|wkwk|wkwkwk|lucu|komedi|kocak)\\b\", \"#komedi\"),\n",
        "        (r\"\\b(marah|emosi|ribut|debat|berantem|panas)\\b\", \"#debat\"),\n",
        "        (r\"\\b(duit|uang|cuan|bisnis|jualan|modal|untung|rugi|investasi|saham|crypto|forex)\\b\", \"#keuangan\"),\n",
        "        (r\"\\b(politik|pemilu|presiden|menteri|dpr)\\b\", \"#politik\"),\n",
        "        (r\"\\b(cinta|pacar|mantan|nikah)\\b\", \"#relationship\"),\n",
        "        (r\"\\b(game|ml|mobile legends|valorant|pubg|ff|free fire)\\b\", \"#gaming\"),\n",
        "        (r\"\\b(makanan|kuliner|masak|pedas|enak)\\b\", \"#kuliner\"),\n",
        "    ]\n",
        "    extras = []\n",
        "    for pat, tag in topic_rules:\n",
        "        if re.search(pat, text_lc):\n",
        "            extras.append(tag)\n",
        "\n",
        "    if re.search(r\"\\b(anjir|anjay|gila|parah|buset|astaga|waduh|yaampun)\\b\", text_lc):\n",
        "        extras.append(\"#chaos\")\n",
        "    if re.search(r\"\\b(ternyata|plot|twist)\\b\", text_lc):\n",
        "        extras.append(\"#plottwist\")\n",
        "\n",
        "    vs = float(s.get(\"viral_score\", 0.0))\n",
        "    if vs >= 80:\n",
        "        extras.append(\"#viral\")\n",
        "\n",
        "    tags = _dedupe_keep_order(base + extras)\n",
        "    return caption, tags[:8]\n",
        "\n",
        "# =========================\n",
        "# Cell: Stage 13 - Run\n",
        "# Manifest (locked JSON/CSV) + Caption/Hashtag (LOG ONLY, non-core)\n",
        "# =========================\n",
        "\n",
        "with StageTimer(13, \"Manifest (locked JSON/CSV) + Caption/Hashtag (log-only)\"):\n",
        "    manifest = {\n",
        "        \"version\": \"v5.5\",\n",
        "        \"video\": str(VIDEO_PATH),\n",
        "        \"run_dir\": str(RUN_DIR),\n",
        "        \"artifacts_dir\": str(ART_DIR),\n",
        "        \"outputs_dir\": str(OUT_DIR),\n",
        "        \"clips\": []\n",
        "    }\n",
        "\n",
        "    for rank, c in enumerate(SELECTED, 1):\n",
        "        cid = c[\"id\"]\n",
        "        transcript_text = \"\"\n",
        "        if \"TRANSCRIPTS\" in globals() and isinstance(TRANSCRIPTS, dict):\n",
        "            transcript_text = (TRANSCRIPTS.get(cid, {}) or {}).get(\"text\", \"\") or \"\"\n",
        "\n",
        "        caption, hashtags = build_caption_and_hashtags(c, transcript_text)\n",
        "\n",
        "        # attach to selected (for LOG TABLE preview only) ‚Äî idempotent\n",
        "        if (not c.get(\"caption\")) or (not c.get(\"hashtags\")):\n",
        "            c[\"caption\"] = caption\n",
        "            c[\"hashtags\"] = hashtags\n",
        "\n",
        "        item = {\n",
        "            \"rank\": int(rank),\n",
        "            \"id\": str(cid),\n",
        "            \"start\": float(c[\"start\"]),\n",
        "            \"end\": float(c[\"end\"]),\n",
        "            \"duration\": float(c[\"duration\"]),\n",
        "            \"viral_score\": float((c.get(\"scores\", {}) or {}).get(\"viral_score\", 0.0)),\n",
        "            \"clip_path\": str(CLIPS_DIR / f\"clip_{rank:02d}_{cid}.mp4\"),\n",
        "            \"thumbnail_path\": str(THUMBS_DIR / f\"thumb_{rank:02d}_{cid}.jpg\"),\n",
        "            \"editorial_reason\": c.get(\"editorial_reason\", []),\n",
        "        }\n",
        "        manifest[\"clips\"].append(item)\n",
        "\n",
        "        # Write manifests both to run folder (locked) and to /kaggle/working root (compat)\n",
        "    manifest_json_path = RUN_DIR / \"manifest.json\"\n",
        "    manifest_csv_path  = RUN_DIR / \"manifest.csv\"\n",
        "    write_json(manifest_json_path, manifest)\n",
        "\n",
        "    root_manifest_json = WORKDIR / \"manifest.json\"\n",
        "    root_manifest_csv  = WORKDIR / \"manifest.csv\"\n",
        "    write_json(root_manifest_json, manifest)\n",
        "\n",
        "    def _write_manifest_csv(path: Path):\n",
        "        with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            fieldnames = [\n",
        "                \"rank\",\"id\",\"start\",\"end\",\"duration\",\"viral_score\",\n",
        "                \"clip_path\",\"thumbnail_path\",\"editorial_reason\"\n",
        "            ]\n",
        "            w = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "            w.writeheader()\n",
        "            for it in manifest[\"clips\"]:\n",
        "                row = dict(it)\n",
        "                er = row.get(\"editorial_reason\", [])\n",
        "                row[\"editorial_reason\"] = \" | \".join(er) if isinstance(er, list) else str(er)\n",
        "                w.writerow(row)\n",
        "\n",
        "    _write_manifest_csv(manifest_csv_path)\n",
        "    _write_manifest_csv(root_manifest_csv)\n",
        "\n",
        "    logger.info(f\"Wrote: {manifest_json_path}\")\n",
        "    logger.info(f\"Wrote: {manifest_csv_path}\")\n",
        "    logger.info(f\"Wrote: {root_manifest_json}\")\n",
        "    logger.info(f\"Wrote: {root_manifest_csv}\")\n",
        "    log_flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125f702f-0d9f-4324-a53c-ed93d633ee01",
      "metadata": {},
      "source": [
        "## ‚úÖ Stage 14: Acceptance Tests & Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4447e7-72ec-4542-816b-eb80ae650373",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-30T12:04:50.463447Z",
          "iopub.status.idle": "2026-01-30T12:04:50.463794Z",
          "shell.execute_reply": "2026-01-30T12:04:50.463643Z",
          "shell.execute_reply.started": "2026-01-30T12:04:50.463618Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Stage 14: Acceptance Tests & Summary\n",
        "# =========================\n",
        "\n",
        "with StageTimer(14, \"Acceptance Tests\"):\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 1) Outputs existence\n",
        "    # -------------------------------------------------\n",
        "    assert CLIPS_DIR.exists(), \"Missing outputs/clips\"\n",
        "    assert THUMBS_DIR.exists(), \"Missing outputs/thumbnails\"\n",
        "    assert (RUN_DIR / \"manifest.json\").exists(), \"Missing runs/<run_id>/manifest.json\"\n",
        "    assert (RUN_DIR / \"manifest.csv\").exists(), \"Missing runs/<run_id>/manifest.csv\"\n",
        "    # also keep root manifests for convenience\n",
        "    assert (WORKDIR / \"manifest.json\").exists(), \"Missing /kaggle/working/manifest.json\"\n",
        "    assert (WORKDIR / \"manifest.csv\").exists(), \"Missing /kaggle/working/manifest.csv\"\n",
        "\n",
        "    clips = sorted(CLIPS_DIR.glob(\"*.mp4\"))\n",
        "    thumbs = sorted(THUMBS_DIR.glob(\"*.jpg\"))\n",
        "\n",
        "    assert len(clips) > 0, \"No exported clips\"\n",
        "    assert len(thumbs) > 0, \"No exported thumbnails\"\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 2) Export format check (first clip)\n",
        "    # -------------------------------------------------\n",
        "    probe = json.loads(\n",
        "        subprocess.check_output([\n",
        "            FFPROBE_BIN, \"-v\", \"error\",\n",
        "            \"-select_streams\", \"v:0\",\n",
        "            \"-show_entries\", \"stream=width,height,r_frame_rate\",\n",
        "            \"-of\", \"json\",\n",
        "            str(clips[0])\n",
        "        ]).decode(\"utf-8\")\n",
        "    )\n",
        "\n",
        "    st = probe[\"streams\"][0]\n",
        "    w = int(st[\"width\"])\n",
        "    h = int(st[\"height\"])\n",
        "\n",
        "    assert (w, h) == (EXPORT_W, EXPORT_H), (\n",
        "        f\"Bad resolution {w}x{h}, expected {EXPORT_W}x{EXPORT_H}\"\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 3) Ensure no subtitle stream\n",
        "    # -------------------------------------------------\n",
        "    probe2 = json.loads(\n",
        "        subprocess.check_output([\n",
        "            FFPROBE_BIN, \"-v\", \"error\",\n",
        "            \"-show_entries\", \"stream=codec_type\",\n",
        "            \"-of\", \"json\",\n",
        "            str(clips[0])\n",
        "        ]).decode(\"utf-8\")\n",
        "    )\n",
        "\n",
        "    types = [s[\"codec_type\"] for s in probe2.get(\"streams\", [])]\n",
        "    assert \"subtitle\" not in types, \"Subtitle stream detected (forbidden).\"\n",
        "\n",
        "# =====================================================\n",
        "# v5.5 ‚Äî Selection Summary (Audit Log)\n",
        "# =====================================================\n",
        "try:\n",
        "    audit_path = ART_DIR / \"selection_audit.json\"\n",
        "    if audit_path.exists():\n",
        "        audit = read_json(audit_path)\n",
        "        selected_rows = [a for a in audit if a.get(\"decision\") == \"selected\"]\n",
        "        rejected_rows = [a for a in audit if a.get(\"decision\") == \"rejected\"]\n",
        "\n",
        "        logger.info(\"=== SELECTION SUMMARY ===\")\n",
        "        logger.info(f\"Candidates total: {len(CANDIDATES)}\")\n",
        "\n",
        "        if CANDIDATES:\n",
        "            top_score = max(\n",
        "                c.get(\"scores\", {}).get(\"viral_score\", 0.0)\n",
        "                for c in CANDIDATES\n",
        "            )\n",
        "            logger.info(f\"Top viral_score: {top_score:.1f}\")\n",
        "\n",
        "        logger.info(f\"Selected: {len(selected_rows)} | Rejected (logged): {len(rejected_rows)}\")\n",
        "\n",
        "        from collections import Counter\n",
        "        rc = Counter([r.get(\"reason\", \"\") for r in rejected_rows])\n",
        "\n",
        "        logger.info(\"Top reject reasons:\")\n",
        "        for k, v in rc.most_common(8):\n",
        "            logger.info(f\" - {k}: {v}\")\n",
        "    else:\n",
        "        logger.warning(\"selection_audit.json not found ‚Äî summary skipped\")\n",
        "\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Selection summary unavailable: {e}\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Final success log\n",
        "# -------------------------------------------------\n",
        "logger.info(\"‚úÖ Acceptance tests passed.\")\n",
        "logger.info(f\"Clips: {len(clips)} | Thumbnails: {len(thumbs)}\")\n",
        "logger.info(f\"Outputs dir: {OUT_DIR}\")\n",
        "logger.info(f\"Run artifacts: {ART_DIR}\")\n",
        "\n",
        "\n",
        "# --- AGENTS.md invariant checks ---\n",
        "try:\n",
        "    # novelty constant check\n",
        "    nov_vals = [float(c.get(\"scores\", {}).get(\"novelty\", 0.0)) for c in CANDIDATES]\n",
        "    nov_unique = set([round(v, 2) for v in nov_vals])\n",
        "    if len(nov_unique) <= 1:\n",
        "        raise RuntimeError(\"ERROR: novelty constant; possible missing transcripts\")\n",
        "\n",
        "    # selection_audit reason codes\n",
        "    audit = read_json(ART_DIR / \"selection_audit.json\") if (ART_DIR / \"selection_audit.json\").exists() else []\n",
        "    if not audit or any((not a.get(\"reason\")) for a in audit):\n",
        "        raise RuntimeError(\"ERROR: selection_audit missing reason codes\")\n",
        "\n",
        "    # late bucket quota check\n",
        "    late_bucket = 4\n",
        "    if (OUT_DIR / \"bucket_stats.json\").exists():\n",
        "        bs = read_json(OUT_DIR / \"bucket_stats.json\")\n",
        "        b4 = bs.get(str(late_bucket), bs.get(late_bucket, {}))\n",
        "        if b4.get(\"meaning_candidates\", 0) > 0 and b4.get(\"selected\", 0) < 1:\n",
        "            raise RuntimeError(\"ERROR: bucket 80-100% quota missed while meaning candidates exist\")\n",
        "\n",
        "    # copy pipeline log\n",
        "    try:\n",
        "        plog = OUT_DIR / \"pipeline_log.txt\"\n",
        "        if LOG_FILE.exists():\n",
        "            plog.write_text(LOG_FILE.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(str(e))\n",
        "    raise\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 9373139,
          "sourceId": 14671719,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}